{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ElasticSearch_nori.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MunJinSeo/elasticsearch/blob/main/ElasticSearch_nori.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDZS1SqudyP5"
      },
      "source": [
        "## **BDC103 빅데이터와정보검색 - 21년1학기 중간고사 대체 과제 **\n",
        "- 빅데이터융합과 서문진, 학번:2020511021\n",
        "\n",
        "## References\n",
        "- (1) **BDC103(00) 빅데이터와정보검색 강의 실습 2강** - 소스\n",
        "   서재형, 임희석 [고려대학교 자연어처리 연구실]\n",
        "\n",
        "- (2) ElasticSearch 공식 홈페이지 : 본과제는 7.8.0 버젼 사용함<br>\n",
        "https://www.elastic.co/kr/what-is/elasticsearch\n",
        "\n",
        "- (3) 한글 형태소 분석기 사용(Nori)<br>\n",
        "https://issues.apache.org/jira/browse/LUCENE-8231 <br>\n",
        "https://github.com/apache/lucene-solr/tree/master/lucene/analysis/nori <br>\n",
        "https://jvvp.tistory.com/1158?category=875256 <br>\n",
        "\n",
        "- (4) Wiki데이터 추출기 : WikiExtractor <br>\n",
        " https://github.com/attardi/wikiextractor\n",
        "\n",
        "\n",
        "## Dataset : 위키 데이터\n",
        "- 영어 - https://dumps.wikimedia.org/enwiki/\n",
        "- 한글 - https://dumps.wikimedia.org/kowiki/\n",
        "\n",
        "## 실행 방법 / 유의사항\n",
        "- Colab 일반 환경 실행\n",
        "- 본인 구글Drive 연결하여 마운트 필요\n",
        "- 소스는 위에서부터 순차적으로 실행\n",
        "- Elasticsearch 서버는 Colab 세션이 끊기면 다시 설치 및 구동 필요\n",
        "\n",
        "## 처리 순서 \n",
        "- ElasticSearch 개요\n",
        "- Clab과 Google Drive 연동하기\n",
        "- Elasticsearch 서버 설치\n",
        "- 한글 형태소 분석기 Nori 설치\n",
        "- Elasticsearch 서버 구동 및 Python 연동\n",
        "- 현재 작업 폴더 재설정하기\n",
        "- 인덱싱 TEST\n",
        "- 색인화 TEST\n",
        "- Wiki 데이터(한글) 다운로드\n",
        "- Wiki데이터 전처리(WikiExtractor)\n",
        "- 검색기 작성 - Wiki데이터(한글) 데이터\n",
        "- (END)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR5VDJ1HJfZp"
      },
      "source": [
        "## ElasticSearch 개요\n",
        "\n",
        "공식 홈페이지 참조: https://www.elastic.co/kr/what-is/elasticsearch\n",
        "\n",
        "#### ElasticSearch란?\n",
        "\n",
        "> Elasticsearch는 **텍스트, 숫자, 위치 기반 정보, 정형 및 비정형 데이터 등 모든 유형의 데이터를 위한 무료 검색 및 분석 엔진으로 분산형 및 개방형을 특징**으로 합니다. Elasticsearch는 Apache Lucene을 기반으로 구축되었으며, Elasticsearch N.V.(현재 명칭 Elastic)가 2010년에 최초로 출시했습니다. 간단한 REST API, 분산형 특징, 속도, 확장성으로 유명한 Elasticsearch는 데이터 수집, 보강, 저장, 분석, 시각화를 위한 무료 개방형 도구 모음인 Elastic Stack의 핵심 구성 요소입니다.\n",
        "\n",
        "#### ElasticSearch에서 색인이란?\n",
        "\n",
        "> Elasticsearch **인덱스는 서로 관련되어 있는 문서들의 모음**입니다. Elasticsearch는 **JSON 문서로 데이터를 저장**합니다. 각 문서는 **일련의 키**(필드나 속성의 이름)와 **그에 해당하는 값**(문자열, 숫자, 부울, 날짜, 값의 배열, 지리적 위치 또는 기타 데이터 유형)을 서로 연결합니다.\n",
        "\n",
        "> Elasticsearch는 **역 인덱스**라고 하는 데이터 구조를 사용하는데, 이것은 아주 빠른 풀텍스트 검색을 할 수 있도록 설계된 것입니다. 역 인덱스는 **문서에 나타나는 모든 고유한 단어의 목록을 만들고, 각 단어가 발생하는 모든 문서를 식별**합니다.\n",
        "\n",
        "> 색인 프로세스 중에, **Elasticsearch는 문서를 저장하고 역 인덱스를 구축하여 거의 실시간으로 문서를 검색** 가능한 데이터로 만듭니다. 인덱스 API를 사용해 색인이 시작되며, 이를 통해 사용자는 특정한 인덱스에서 JSON 문서를 추가하거나 업데이트할 수 있습니다.\n",
        "\n",
        "#### 사용하는 이유?\n",
        "\n",
        "> Elasticsearch는 Lucene을 기반으로 구축되기 때문에, **풀텍스트 검색에 뛰어납니다**. Elasticsearch는 또한 거의 **실시간 검색 플랫폼**입니다. 이것은 문서가 색인될 때부터 검색 가능해질 때까지의 대기 시간이 아주 짧다는 뜻입니다. 이 대기 시간은 보통 1초입니다.\n",
        "\n",
        "> 분산 시스템으로 **병렬적인 처리. 검색 대상의 사이즈가 아주 크더라도 분석 및 처리가 가능**합니다.\n",
        "\n",
        "**--> 빅데이터 검색에 적합한 검색 엔진**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuJ97wRkZIZr"
      },
      "source": [
        "## Clab과 Google Drive 연동하기\n",
        "\n",
        "구글 코랩 환경에서는 로그인되어 있는 구글 계정과 연결되어 있는 '구글 드라이브'와의 연동을 지원함.  \n",
        "연동하는 경우, 자신의 구글 드라이브를 로컬 환경처럼 활용 가능."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZGi15R3ZBNE"
      },
      "source": [
        "### Google Drive 패키지와 os 모듈 불러오기\n",
        "from google.colab import drive\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QESTJMWZJgs",
        "outputId": "331261a2-5ce8-4b02-aa00-8180112ef087"
      },
      "source": [
        "### 본인 구글 드라이브의 최초 경로를 설정하기\n",
        "\n",
        "# 대부분의 구글 드라이브 최초 경로는 아래와 같습니다. \n",
        "# 예외 발생 시 본인의 구글 드라이브에 접속하여 content 폴더나 gdrive 폴더가 어떤 위치에 있으며, \n",
        "# 자신이 연결하려는 폴더까지의 경로가 어떻게 되는지 확인해야 합니다.  \n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BGTF2zT6ZMp6",
        "outputId": "85c9414b-70d3-48e9-8bca-7722b93e6ab4"
      },
      "source": [
        "### 자신의 현재 경로를 파악하기\n",
        "\n",
        "os.getcwd() ## /content로 나올 것."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwRCwpRm1ije"
      },
      "source": [
        "## Elasticsearch 서버 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_DmUR_krAJN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "994b8ab0-0806-485e-f84a-ed2a27b6e7dc"
      },
      "source": [
        "### 구글 클라우드 컴퓨터에 elastic server 서버 설치를 위한 폴더 생성 \n",
        "!sudo mkdir /content/elasticsearch\n",
        "### 접근 권한 수정\n",
        "!chmod 755 -R elasticsearch\n",
        "### 현재 작업 디렉토리 설정\n",
        "os.chdir('/content/elasticsearch')\n",
        "\n",
        "## 현재 dir 정보 출력\n",
        "! pwd \n",
        "! ls -lart"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/elasticsearch\n",
            "total 8\n",
            "drwxr-xr-x 1 root root 4096 May  5 08:35 ..\n",
            "drwxr-xr-x 2 root root 4096 May  5 08:35 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CcNnHCosV4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dba0dff1-4b5b-44e8-bdeb-e4a4944fb525"
      },
      "source": [
        "### 리눅스용 엘라스틱서치 서버 설치를 위한 패키지 다운로드\n",
        "#!wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.0.0-linux-x86_64.tar.gz -q\n",
        "!wget -q https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.8.0-linux-x86_64.tar.gz\n",
        "#!wget -q https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.12.1-linux-x86_64.tar.gz\n",
        "! ls -lart"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 311648\n",
            "-rw-r--r-- 1 root root 319112561 Jun 18  2020 elasticsearch-7.8.0-linux-x86_64.tar.gz\n",
            "drwxr-xr-x 1 root root      4096 May  5 08:35 ..\n",
            "drwxr-xr-x 2 root root      4096 May  5 08:35 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4UVAmFWsd_Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ebbdd8f-dfd1-4af7-a178-6917c923ff3d"
      },
      "source": [
        "### 위에서 다운로드 받은 압축 파일을 해제\n",
        "#!tar -xzf elasticsearch-7.0.0-linux-x86_64.tar.gz\n",
        "!tar -xzf elasticsearch-7.8.0-linux-x86_64.tar.gz\n",
        "#!tar -xzf elasticsearch-7.12.1-linux-x86_64.tar.gz\n",
        "!ls -lart"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 311652\n",
            "drwxr-xr-x 9 root root      4096 Jun 14  2020 elasticsearch-7.8.0\n",
            "-rw-r--r-- 1 root root 319112561 Jun 18  2020 elasticsearch-7.8.0-linux-x86_64.tar.gz\n",
            "drwxr-xr-x 1 root root      4096 May  5 08:35 ..\n",
            "drwxr-xr-x 3 root root      4096 May  5 08:35 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfUtZwAHskoH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92d80c19-222c-40f5-bd08-aa0bf4a3fdda"
      },
      "source": [
        "### 코랩 노트북 환경에서 서버 구동을 위해서 PPID 1의 백그라운드 데몬 프로세스가 해당 폴더에 접근이 가능하도록 소유자 변경\n",
        "#!chown -R daemon:daemon elasticsearch-7.0.0 \n",
        "!chown -R daemon:daemon elasticsearch-7.8.0 \n",
        "#!chown -R daemon:daemon elasticsearch-7.12.1 \n",
        "!ls -lart"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 311652\n",
            "drwxr-xr-x 9 daemon daemon      4096 Jun 14  2020 elasticsearch-7.8.0\n",
            "-rw-r--r-- 1 root   root   319112561 Jun 18  2020 elasticsearch-7.8.0-linux-x86_64.tar.gz\n",
            "drwxr-xr-x 1 root   root        4096 May  5 08:35 ..\n",
            "drwxr-xr-x 3 root   root        4096 May  5 08:35 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgiEQ3tcv0X_"
      },
      "source": [
        "## 한글 형태소 분석기 Nori 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBamQWpeWd4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e80417a-ef82-4f09-a0a9-2d45f144b690"
      },
      "source": [
        "# 한글 형태소 분석기 설치\n",
        "#! ./elasticsearch-7.0.0/bin/elasticsearch-plugin install analysis-nori\n",
        "! ./elasticsearch-7.8.0/bin/elasticsearch-plugin install analysis-nori\n",
        "#! ./elasticsearch-7.12.1/bin/elasticsearch-plugin install analysis-nori"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-> Installing analysis-nori\n",
            "-> Downloading analysis-nori from elastic\n",
            "[=================================================] 100%   \n",
            "-> Installed analysis-nori\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9E3Q2y13Ygq",
        "outputId": "d2ec2a10-8696-4024-91a8-4adcd7014c5b"
      },
      "source": [
        "# 플러그인 설치 확인\n",
        "! ./elasticsearch-7.8.0/bin/elasticsearch-plugin list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "analysis-nori\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0xZsPWw4-n6"
      },
      "source": [
        "## Elasticsearch 서버 구동 및 Python 연동\n",
        "\n",
        "> /content/gdrive 이후의 경로에는 구글 드라이브 보안으로 인해서\n",
        "daemon process가 정상적인 방식으로는 서버 구동이 어렵기 때문에 본인 드라이브가 아닌 구글 클라우드 컴퓨터에 엘라스틱 서버를 설치하고 개시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Jjugup6tEF6",
        "outputId": "60bc4373-a439-4238-e6df-3910c8bc8004"
      },
      "source": [
        "### 파이썬 환경에서 구동을 위한 elasticsearch 패키지 설치\n",
        "#!pip uninstall elasticsearch\n",
        "!pip install elasticsearch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting elasticsearch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/5c/60a32dfc24da07703b5b32d9935bcc36786a9176e67117c4b6215fd6d914/elasticsearch-7.12.1-py2.py3-none-any.whl (339kB)\n",
            "\r\u001b[K     |█                               | 10kB 15.1MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 8.7MB/s eta 0:00:01\r\u001b[K     |███                             | 30kB 6.0MB/s eta 0:00:01\r\u001b[K     |███▉                            | 40kB 5.8MB/s eta 0:00:01\r\u001b[K     |████▉                           | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 61kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 71kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 81kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 92kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 102kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 112kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 122kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 133kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 143kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 153kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 163kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 174kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 184kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 194kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 204kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 215kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 225kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 235kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 245kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 256kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 266kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 276kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 286kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 296kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 307kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 317kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 327kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 337kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 348kB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elasticsearch) (2020.12.5)\n",
            "Requirement already satisfied: urllib3<2,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from elasticsearch) (1.24.3)\n",
            "Installing collected packages: elasticsearch\n",
            "Successfully installed elasticsearch-7.12.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDzbifJStJmw"
      },
      "source": [
        "# 데몬 프로세스로 엘라스틱 서버 개시하기\n",
        "\n",
        "# 리눅스에서는 sudo systemctl restart elasticsearch\n",
        "\n",
        "import os\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "#es = Popen(['elasticsearch-7.0.0/bin/elasticsearch'], \n",
        "es = Popen(['elasticsearch-7.8.0/bin/elasticsearch'], \n",
        "                  stdout=PIPE, stderr=STDOUT,\n",
        "                  preexec_fn=lambda: os.setuid(1)  # as daemon\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQgw-4rLpfJD",
        "outputId": "f8721393-9d01-43df-e479-51402dd1eb45"
      },
      "source": [
        "# 약1~3분후 elasticsearch 구동 확인\n",
        "! vmstat 1 -t 60\n",
        "! ps -elf | grep elasticsearch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- -----timestamp-----\n",
            " r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st                 UTC\n",
            " 2  0      0 7638644  79848 3730104    0    0  1859  1700  491  800 10  3 85  2  0 2021-05-05 08:37:13\n",
            " 2  0      0 7615812  79848 3730200    0    0     0     0 2549 1994 87  2 11  0  0 2021-05-05 08:37:14\n",
            " 3  0      0 7610708  81144 3731788    0    0     0  4708 3889 6029 82  6  3  9  0 2021-05-05 08:37:15\n",
            "4 S daemon       423      58 99  80   0 - 732776 futex_ 08:36 ?       00:00:38 /content/elasticsearch/elasticsearch-7.8.0/jdk/bin/java -Xshare:auto -Des.networkaddress.cache.ttl=60 -Des.networkaddress.cache.negative.ttl=10 -XX:+AlwaysPreTouch -Xss1m -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djna.nosys=true -XX:-OmitStackTraceInFastThrow -XX:+ShowCodeDetailsInExceptionMessages -Dio.netty.noUnsafe=true -Dio.netty.noKeySetOptimization=true -Dio.netty.recycler.maxCapacityPerThread=0 -Dio.netty.allocator.numDirectArenas=0 -Dlog4j.shutdownHookEnabled=false -Dlog4j2.disable.jmx=true -Djava.locale.providers=SPI,COMPAT -Xms1g -Xmx1g -XX:+UseG1GC -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -Djava.io.tmpdir=/tmp/elasticsearch-3526022779714599308 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=data -XX:ErrorFile=logs/hs_err_pid%p.log -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m -XX:MaxDirectMemorySize=536870912 -Des.path.home=/content/elasticsearch/elasticsearch-7.8.0 -Des.path.conf=/content/elasticsearch/elasticsearch-7.8.0/config -Des.distribution.flavor=default -Des.distribution.type=tar -Des.bundled_jdk=true -cp /content/elasticsearch/elasticsearch-7.8.0/lib/* org.elasticsearch.bootstrap.Elasticsearch\n",
            "4 S daemon       609     423  0  80   0 - 28106 pipe_r 08:36 ?        00:00:00 /content/elasticsearch/elasticsearch-7.8.0/modules/x-pack-ml/platform/linux-x86_64/bin/controller\n",
            "0 S root         658      58  0  80   0 -  9800 wait   08:37 ?        00:00:00 /bin/bash -c  ps -elf | grep elasticsearch\n",
            "0 S root         660     658  0  80   0 -  9644 pipe_r 08:37 ?        00:00:00 grep elasticsearch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZD2PfkXt9Xy",
        "outputId": "393bb5ba-e380-4028-c717-243cc8effe48"
      },
      "source": [
        "# 로컬 서버에 엘라스틱 서버와 python을 연결\n",
        "from elasticsearch import Elasticsearch\n",
        "es = Elasticsearch(\"localhost:9200/\")\n",
        "es.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cluster_name': 'elasticsearch',\n",
              " 'cluster_uuid': '175LW-siQp6oH_aX8gymag',\n",
              " 'name': 'db0852987eb6',\n",
              " 'tagline': 'You Know, for Search',\n",
              " 'version': {'build_date': '2020-06-14T19:35:50.234439Z',\n",
              "  'build_flavor': 'default',\n",
              "  'build_hash': '757314695644ea9a1dc2fecd26d1a43856725e65',\n",
              "  'build_snapshot': False,\n",
              "  'build_type': 'tar',\n",
              "  'lucene_version': '8.5.1',\n",
              "  'minimum_index_compatibility_version': '6.0.0-beta1',\n",
              "  'minimum_wire_compatibility_version': '6.8.0',\n",
              "  'number': '7.8.0'}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP_W53wH5ZRr"
      },
      "source": [
        "## 현재 작업 폴더 재설정하기\n",
        "(자신만의 작업 디렉토리를 기본 경로로 설정하는 것)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsuXyBkVZPxA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99d5f8b5-e777-45ed-ba7c-ed4965f02de5"
      },
      "source": [
        "#.ipynb 노트북 파일과 불러오려는 이미지 및 모듈에 해당하는 파일들은 같은 현재 작업 환경 하위 폴더에 존재하는 것이 좋습니다. \n",
        "\n",
        "# 자신만의 기본 경로를 설정하는데, 대부분의 경우에는 Colab Notebooks까지 동일하게 공유하며,\n",
        "# 이후 경로는 자신이 생성한 폴더에 맞추어서 경로를 설정하면 됩니다.\n",
        "# 수업에서는 자신의 구글 드라이브에 information_retrieval 폴더를 생성하시면 됩니다. \n",
        "os.chdir('/content/gdrive/MyDrive/Colab Notebooks/information_retrieval/')\n",
        "\n",
        "#elastic 폴더 생성\n",
        "!sudo mkdir elastic\n",
        "\n",
        "os.chdir('/content/gdrive/MyDrive/Colab Notebooks/information_retrieval/elastic/')\n",
        "\n",
        "!ls -lart"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 890873\n",
            "-rw------- 1 root root      9731 Apr 15 10:48 tinywiki-latest-pages-articles.xml.bz2\n",
            "drwx------ 2 root root      4096 Apr 15 10:50 wikiextractor\n",
            "drwx------ 2 root root      4096 Apr 15 10:50 extract_result\n",
            "-rw------- 1 root root     12288 Apr 15 10:57 sample_wiki.db\n",
            "-rw------- 1 root root  67535180 May  1 19:42 kowiki-latest-pages-articles1.xml-p1p82407.bz2\n",
            "-rw------- 1 root root 752149591 May  1 19:52 kowiki-latest-pages-articles.xml.bz2\n",
            "-rw------- 1 root root  13470382 May  3 23:44 kowiki-latest-all-titles.gz\n",
            "-rw------- 1 root root  78439689 May  4 00:42 kowiki-latest-abstract.xml.gz\n",
            "-rw------- 1 root root    626688 May  5 04:09 AA_wiki.db\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDsLe1QI1QDo"
      },
      "source": [
        "## 인덱싱 TEST\n",
        "\n",
        "> 딕셔너리 구조의 데이터로 샘플 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlUp5Tsw1NhC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e348933-c513-4fc6-f117-d3aecd0a54a4"
      },
      "source": [
        "# 데이터를 색인화하기 위한 함수\n",
        "def indexing(es, index_name):\n",
        "    # 이미 존재할 경우 삭제하고 다시 만들기\n",
        "    if es.indices.exists(index=index_name):\n",
        "        es.indices.delete(index=index_name)\n",
        "\n",
        "    # 인덱스 생성\n",
        "    print(es.indices.create(index=index_name))\n",
        "\n",
        "# 인덱스명 정의\n",
        "index_name = 'sample_index'\n",
        "indexing(es, index_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'sample_index'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68zDcAB6-rkF"
      },
      "source": [
        "## 색인화 TEST\n",
        "\n",
        "> 변수명, key, value에 해당하는 부분은 자유롭게 작성. 딕셔너리 자료형을 기본으로 하기 때문에, 해당 형식에 맞추어서 만들 수 있음.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f96zbclC_kG7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b81d1c1a-b05c-4040-9636-6b35df21d79b"
      },
      "source": [
        "### 새로운 데이터 인덱싱 \n",
        "## 여기서는 '노래 제목'과 '가사 일부'를 mapping했습니다.\n",
        "sample1= {'songs': '민족의 아리아', 'lyrics': '지축을 박차고 포효하라 그대'}\n",
        "sample2= {'songs': '뱃노래', 'lyrics': '즐거운 고연전 날에 지고 가는 연대생이 처량도 하구나'}\n",
        "sample3= {'songs': '석탑', 'lyrics': '이름모를 석공의 땀과 눈물이 흘러내리네'}\n",
        "sample4= {'songs': 'Forever', 'lyrics': '우리의 함성은 신화가 되리라 울려라 이곳에 Forever'}\n",
        "sample5= {'songs': '젊은그대', 'lyrics': '사랑스런 젊은 그대 태양같은 젊은 그대'}\n",
        "\n",
        "# es 변수에 객체화한 서버는 위에서 정의한 데아터에 대해서\n",
        "# 이전 셀에서 선언한 'sample_index'로 인덱스명을 정하고\n",
        "# 데이터의 타입은 문자열인 상태로 색인화를 진행합니다.\n",
        "es.index(index=index_name, doc_type='string', body = sample1)\n",
        "es.index(index=index_name, doc_type='string', body = sample2)\n",
        "es.index(index=index_name, doc_type='string', body = sample3)\n",
        "es.index(index=index_name, doc_type='string', body = sample4)\n",
        "es.index(index=index_name, doc_type='string', body = sample5)\n",
        "\n",
        "es.indices.refresh(index=index_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/elasticsearch/connection/base.py:200: ElasticsearchWarning: [types removal] Specifying types in document index requests is deprecated, use the typeless endpoints instead (/{index}/_doc/{id}, /{index}/_doc, or /{index}/_create/{id}).\n",
            "  warnings.warn(message, category=ElasticsearchWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_shards': {'failed': 0, 'successful': 1, 'total': 2}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3r0EBhuEFgy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b452a055-7c43-4669-d11b-5ace8e40ba54"
      },
      "source": [
        "# 검색 해보기\n",
        "# es.search(index = '선언한 인덱스명', body = {'from': '몇 위부터 반환할 것인지', 'size': '최대 반환할 갯수', 'query' : {'match':{'기준 key' : '검색할 내용'}}})\n",
        "\n",
        "results = es.search(index=index_name, body={'from':0, 'size':10, 'query':{'match':{'lyrics':'그대'}}})\n",
        "\n",
        "# 딕셔너리 안에 딕셔너리: 'hits'라는 key 안에 value는 또 다른 사전형으로 되어있으며, 해당 사전의 key 이름은 'hits'   \n",
        "for result in results['hits']['hits']:\n",
        "    print('score:', result['_score'], 'source::', result['_source'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score: 1.2037694 source:: {'songs': '젊은그대', 'lyrics': '사랑스런 젊은 그대 태양같은 젊은 그대'}\n",
            "score: 1.0137007 source:: {'songs': '민족의 아리아', 'lyrics': '지축을 박차고 포효하라 그대'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVT31VFMFxFF"
      },
      "source": [
        "## Wiki 데이터(한글) 다운로드\n",
        "\n",
        "영어 - https://dumps.wikimedia.org/enwiki/\n",
        "\n",
        "한글 - https://dumps.wikimedia.org/kowiki/\n",
        "\n",
        "https://ko.wikipedia.org/wiki/위키백과:데이터베이스_다운로드\n",
        "\n",
        "**pages-articles.xml.bz2** - 일반 문서의 최신 버전만이 묶여 있고, 전체\n",
        "편집 이력제외. 대부분의 이 파일을 이용하면 됩니다.<br>\n",
        "pages-current.xml.bz2 - 모든 문서의 최신 버전이 묶여 있습니다.<br>\n",
        "pages-full.xml.bz2/7z - 모든 문서(토론 포함)의 최신 버전이 묶여 있습니다.<br>\n",
        "pages-meta-history.xml.bz2 - 모든 문서의 모든 편집 내역이 묶여 있습니다.<br>\n",
        "pages-logging.xml.gz - 모든 문서와 사용자에 대한 행위 기록이 묶여 있습니다.<br>\n",
        "abstract.xml.gz - 문서 요약이 묶여 있습니다.<br>\n",
        "all-titles.gz - 모든 문서 (토론 포함) 의 제목이 묶여 있습니다.<br>\n",
        "all-titles-in-ns0.gz - 모든 문서 (본문만) 의 제목이 묶여 있습니다.<br>\n",
        "redirect.sql.gz - 넘겨주기 문서의 목록이 묶여 있습니다.<br>\n",
        "pagelinks.sql.gz - 위키 문서 간의 링크가 묶여 있습니다.<br>\n",
        "externallinks.sql.gz - 위키 외부로의 링크가 묶여 있습니다.<br>\n",
        "protected_titles.sql.gz - 위키에서 생성보호된 문서의 제목이 묶여 있습니다.<br>\n",
        "user_groups.sql.gz - 사용자의 권한 목록이 묶여 있습니다.<br>\n",
        "user_former_groups.sql.gz - 과거의 사용자 권한 기록이 묶여 있습니다.<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aDqvMLNg7jC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd78631d-efc4-4e10-dc38-186b898e55c9"
      },
      "source": [
        "# 실습 샘플 영어 위키 덤프를 다운로드\n",
        "#!wget https://github.com/AlonEirew/wikipedia-to-elastic/raw/master/dumps/tinywiki-latest-pages-articles.xml.bz2\n",
        "\n",
        "# 위키 덤프 다운로드(한글 최근 문서 : 약 717MB)\n",
        "#!wget https://dumps.wikimedia.org/kowiki/latest/kowiki-latest-pages-articles.xml.bz2\n",
        "# 위키 덤프 다운로드(한글 최근 문서 p1~p82407 : 약 64MB)\n",
        "!wget https://dumps.wikimedia.org/kowiki/latest/kowiki-latest-pages-articles1.xml-p1p82407.bz2\n",
        "\n",
        "# 위키 덤프 다운로드(한글 최근 제목 : 약 13MB)\n",
        "#!wget https://dumps.wikimedia.org/kowiki/latest/kowiki-latest-all-titles.gz\n",
        "\n",
        "# 위키 덤프 다운로드(한글 요약 : 약 75MB)\n",
        "#!wget https://dumps.wikimedia.org/kowiki/latest/kowiki-latest-abstract.xml.gz\n",
        "\n",
        "!pwd\n",
        "!ls -lart"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-05 08:39:30--  https://dumps.wikimedia.org/kowiki/latest/kowiki-latest-pages-articles1.xml-p1p82407.bz2\n",
            "Resolving dumps.wikimedia.org (dumps.wikimedia.org)... 208.80.154.7, 2620:0:861:1:208:80:154:7\n",
            "Connecting to dumps.wikimedia.org (dumps.wikimedia.org)|208.80.154.7|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67535180 (64M) [application/octet-stream]\n",
            "Saving to: ‘kowiki-latest-pages-articles1.xml-p1p82407.bz2.1’\n",
            "\n",
            "kowiki-latest-pages 100%[===================>]  64.41M  4.52MB/s    in 14s     \n",
            "\n",
            "2021-05-05 08:39:46 (4.44 MB/s) - ‘kowiki-latest-pages-articles1.xml-p1p82407.bz2.1’ saved [67535180/67535180]\n",
            "\n",
            "/content/gdrive/My Drive/Colab Notebooks/information_retrieval/elastic\n",
            "total 956825\n",
            "-rw------- 1 root root      9731 Apr 15 10:48 tinywiki-latest-pages-articles.xml.bz2\n",
            "drwx------ 2 root root      4096 Apr 15 10:50 wikiextractor\n",
            "drwx------ 2 root root      4096 Apr 15 10:50 extract_result\n",
            "-rw------- 1 root root     12288 Apr 15 10:57 sample_wiki.db\n",
            "-rw------- 1 root root  67535180 May  1 19:42 kowiki-latest-pages-articles1.xml-p1p82407.bz2.1\n",
            "-rw------- 1 root root  67535180 May  1 19:42 kowiki-latest-pages-articles1.xml-p1p82407.bz2\n",
            "-rw------- 1 root root 752149591 May  1 19:52 kowiki-latest-pages-articles.xml.bz2\n",
            "-rw------- 1 root root  13470382 May  3 23:44 kowiki-latest-all-titles.gz\n",
            "-rw------- 1 root root  78439689 May  4 00:42 kowiki-latest-abstract.xml.gz\n",
            "-rw------- 1 root root    626688 May  5 04:09 AA_wiki.db\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWTWx1B18DU0"
      },
      "source": [
        "## Wiki데이터 전처리(WikiExtractor)\n",
        "\n",
        "\n",
        "> WikiExtractor https://github.com/attardi/wikiextractor\n",
        "\n",
        "```\n",
        "@misc{Wikiextractor2015,\n",
        "  author = {Giusepppe Attardi},\n",
        "  title = {WikiExtractor},\n",
        "  year = {2015},\n",
        "  publisher = {GitHub},\n",
        "  journal = {GitHub repository},\n",
        "  howpublished = {\\url{https://github.com/attardi/wikiextractor}}\n",
        "}\n",
        "```\n",
        "\n",
        "위키 데이터에 포함되어 있는 불필요한 태그, 특수 문자, 기호, 숫자 등을 제거하고\n",
        "\n",
        "원하는 부분을 별도로 추출이 가능 ex) 문서 본문, 제목, 저자 등"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jijQiwAv2oaD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eda76e10-c457-4d2d-be60-05d5015b127e"
      },
      "source": [
        "# 위키데이터의 노이즈를 제거하고 json 형태로 반환하는 코드를 참조\n",
        "!git clone https://github.com/attardi/wikiextractor.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'wikiextractor' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfm7Hrs6xOaT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d47f8ccf-9aa2-43e0-a9c8-5a242099b211"
      },
      "source": [
        "# 다운로드 받은 샘플 위키 데이터를 전처리하여 검색의 입력으로 사용\n",
        "# 결과는 elastic 폴더에 'extract_result/AA,AB,AC.../wiki_00..99'라는 새로운 폴더에 저장된다.(용량이 비슷하게 나눠서 저장됨)\n",
        "# 변환결과 wiki_00 파일의 내용 샘플  {\"id\": \"5\", \"revid\": \"641228\", \"url\": \"https://ko.wikipedia.org/wiki?curid=5\", \"title\": \"\\uc9c0\\...\\ud130\", \"text\": \"\\uc81c\\...\\ub2e4.\"}\n",
        "#!python -m wikiextractor.wikiextractor.WikiExtractor tinywiki-latest-pages-articles.xml.bz2 --json -o extract_result\n",
        "#!python -m wikiextractor.wikiextractor.WikiExtractor kowiki-latest-pages-articles.xml.bz2 --json -o extract_result\n",
        "!python -m wikiextractor.wikiextractor.WikiExtractor kowiki-latest-pages-articles1.xml-p1p82407.bz2 --json -o extract_result\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO: Preprocessing 'kowiki-latest-pages-articles1.xml-p1p82407.bz2' to collect template definitions: this may take some time.\n",
            "INFO: Loaded 1894 templates in 25.8s\n",
            "INFO: Starting page extraction from kowiki-latest-pages-articles1.xml-p1p82407.bz2.\n",
            "INFO: Using 1 extract processes.\n",
            "INFO: Finished 1-process extraction of 34066 articles in 160.3s (212.5 art/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbCfXwnp6RkC"
      },
      "source": [
        "## 검색기 작성 - Wiki데이터(한글) 데이터\n",
        "(한글 형태소 분석기 Nori적용)\n",
        "\n",
        "* Nori는 Elasticssearch 6.6~이후 버젼부터 공식적으로 개발해서 지원하기 시작함\n",
        "* Nori 는 루씬의 기능으로 개발되었으며 루씬 소스에 반영되어 있으며 개발 이력은 https://issues.apache.org/jira/browse/LUCENE-8231\n",
        "에서 확인 할 수 있고 프로그램 소스는 https://github.com/apache/lucene-solr/tree/master/lucene/analysis/nori 에서 확인이 가능\n",
        "\n",
        "* 참고: https://jvvp.tistory.com/1158?category=875256\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XjwZ66BD_dS",
        "outputId": "6f8e5a20-0c0b-4364-d94e-de61f670bb1a"
      },
      "source": [
        "import pprint\n",
        "import json\n",
        "from elasticsearch import Elasticsearch\n",
        "\n",
        "def create_index(body=None):\n",
        "    if not es.indices.exists(index=index):\n",
        "        if body is None:\n",
        "            rtn = es.indices.create(index=index)\n",
        "        else:\n",
        "            rtn = es.indices.create(index=index, body=body)\n",
        "        return rtn\n",
        "\n",
        "def delete_index():\n",
        "    if es.indices.exists(index=index):\n",
        "        return es.indices.delete(index=index)\n",
        "\n",
        "def insert_body(body):\n",
        "    return es.index(index=index, body=body)\n",
        "\n",
        "def search(keyword=None):\n",
        "    body = {\n",
        "        \"query\": {\n",
        "            \"multi_match\": {\n",
        "                \"query\": keyword,\n",
        "                \"fields\": ['title', 'text']  # wiki에서 json만들어질때 컬럼명이 제목은 title , 내용은 text\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    # es.search(index = '선언한 인덱스명', body = {'from': '몇 위부터 반환할 것인지', 'size': '최대 반환할 갯수', 'query' : {'match':{'기준 key' : '검색할 내용'}}})\n",
        "    res = es.search(index=index, body=body)\n",
        "    return res\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    url = 'localhost'  # elasticsearch 데몬 서버ip\n",
        "    port = '9200'      # elasticsearch 데몬 port\n",
        "    index = 'my_index'  #index 이름 : 임의값 지정\n",
        "    doc_type = 'wiki_dump_json' #임의값 지정\n",
        "\n",
        "    es = Elasticsearch(f'{url}:{port}')\n",
        "    \n",
        "    # 한글 형태소 분석기 Nori 사용 셋팅\n",
        "    #with open('index_nori_setting.json', 'r', encoding='utf-8') as f:\n",
        "    #    setting = json.load(f)\n",
        "\n",
        "    # 위 파일에서 읽지 않고 바로 셋팅함  \"decompound_mode\": \"mixed\"\n",
        "    setting = {\n",
        "      \"settings\": {\n",
        "        \"analysis\": {\n",
        "          \"analyzer\": {\n",
        "            \"content\": {\n",
        "              \"type\": \"custom\",\n",
        "              \"tokenizer\": \"nori_tokenizer\",\n",
        "              \"decompound_mode\": \"mixed\"\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      },\n",
        "      \"mappings\": {\n",
        "        \"properties\": {\n",
        "          \"title\": { # wiki에서 json파일 생성시 컬럼명이 title임\n",
        "            \"type\": \"text\",\n",
        "            \"analyzer\": \"content\" #위쪽 settings 하위에 analyzer의 content조건 사용\n",
        "          },\n",
        "          \"text\": { # wiki에서 json파일 생성시 컬럼명이 text임\n",
        "            \"type\": \"text\", #여기 text는 형태를 나타냄, 윗줄의 text랑 다름\n",
        "            \"analyzer\": \"content\" #위쪽 settings 하위에 analyzer의 content조건 사용\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "        \n",
        "    delete_index()    \n",
        "    #create_index() # default\n",
        "    create_index(setting) # nori 적용\n",
        "\n",
        "    pprint.pprint(es.indices.get_settings(index))\n",
        "\n",
        "    #with open('wiki_dump_data.json', 'r', encoding='utf-8') as f:\n",
        "    wiki_dump_json_file = '/content/gdrive/MyDrive/Colab Notebooks/information_retrieval/elastic/extract_result/AA/wiki_00'\n",
        "    #! head '{wiki_dump_json_file}'\n",
        "\n",
        "    #with open(wiki_dump_json_file, 'r', encoding='utf-8') as f:\n",
        "    #    json_data = json.load(f)\n",
        "    #for d in json_data:\n",
        "    #    insert_body(d)\n",
        "\n",
        "    # 위쪽 방법은 json 양식에서 {}괄호 가장 뒤에 쉼표(,)가 있어야하는데, 없어서 json에러나기 때문에 아래처럼 처리함\n",
        "    cnt = 0\n",
        "    for line in open(wiki_dump_json_file, encoding=\"utf-8\"):\n",
        "      #line = line.replace('\"text\"','\"cont\"')\n",
        "      #if (cnt == 0) : print(line)\n",
        "      json_data = json.loads(line)\n",
        "      #if (cnt == 0) : print(json_data['title'],'----',json_data['text'])\n",
        "      insert_body(json_data)\n",
        "      cnt = cnt +1\n",
        "    \n",
        "    print(\"total insert_body lines = \",cnt)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'my_index': {'settings': {'index': {'analysis': {'analyzer': {'content': {'decompound_mode': 'mixed',\n",
            "                                                                           'tokenizer': 'nori_tokenizer',\n",
            "                                                                           'type': 'custom'}}},\n",
            "                                     'creation_date': '1620204347556',\n",
            "                                     'number_of_replicas': '1',\n",
            "                                     'number_of_shards': '1',\n",
            "                                     'provided_name': 'my_index',\n",
            "                                     'uuid': 'H9fnmibbSqiYnQJ1Ymz8bw',\n",
            "                                     'version': {'created': '7080099'}}}}}\n",
            "total insert_body lines =  93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5ligk5Eb9Bh",
        "outputId": "4f1ea223-eef6-4898-dd50-70c6de5a972a"
      },
      "source": [
        "    # 검색해보기\n",
        "    rs = search('싱어송라이터 영화배우')\n",
        "    #pprint.pprint(rs)\n",
        "    \n",
        "    #if rs:\n",
        "    #  for doc in rs['hits']['hits']:\n",
        "    #    for k, v in doc['_source'].items():\n",
        "    #      print(k, v)\n",
        "\n",
        "    #결과 출력\n",
        "    for rst in rs['hits']['hits']:\n",
        "      print('score:', rst['_score'], 'source::', rst['_source'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score: 17.503517 source:: {'id': '195', 'revid': '27385573', 'url': 'https://ko.wikipedia.org/wiki?curid=195', 'title': '빅토르 초이', 'text': '빅토르 로베르토비치 초이(, 1962년 6월 21일 ~ 1990년 8월 15일)는 소련의 록 가수이자, 싱어송라이터 겸 영화배우이며, 소련 록 음악 밴드 키노(КИНО)의 리더였다.\\n생애.\\n데뷔 이전.\\n빅토르 초이는 1962년 6월 21일, 소련 레닌그라드에서 아버지 로베르트 막시모비치 초이(최동열)와 우크라이나계 러시아인 출신 어머니 사이에서 슬하 무녀독남 외동아들로 출생하였다. 친조부 막심 초이(최승준)는 본래 대한제국 함경북도 성진 출생이었고 후일 일제 강점기 초기에 러시아 제국으로 건너간 고려인 출신이었다. 소련 레닌그라드에서 출생하였으며 지난날 한 때 소련 카자흐스탄 사회주의 자치공화국 키질로르다에서 잠시 유아기를 보낸 적이 있는 그는 17세 때부터 노래를 작곡하기 시작했으며, 초기 곡들은 레닌그라드 거리에서의 삶, 사랑과 친구들과의 어울림 등을 다루고 있다. 노래의 주인공은 주로 한정된 기회만이 주어진 채 각박한 세상을 살아나가려는 젊은이였다. 이 시기에 록은 레닌그라드에서만 태동하고 있던 언더그라운드의 한 움직임이었으며, 음악 차트 등의 대중 매체들은 모스크바의 팝 스타들이 장악하고 있었다. 소련 정부는 자신들의 입맛에 맞는 가수들에게만 허가를 내 주었고, 집과 녹음실 등 성공이 필요한 많은 것들을 제공하여 길들였다. 그러나 록 음악은 그 당시 소련 정부에게 너무도 마땅치 않은 음악이었다. 록은 자본주의 진영의 록 그룹의 영향을 받았다는 것 외에도 젊은이들을 반항적으로 만들었으며, 의사 표현의 자유 등 표현 관련 가치를 중시했다. 따라서 록 밴드들은 정부로부터 거의 원조를 받지 못했고 관영 매체에 의해 마약 중독자나 부랑자라는 편견으로 그려지는 수준이었다.\\n빅토르 초이는 레닌그라드에 있는 세로프 미술전문학교에 입학였으나, 결국 낮은 성적 때문에 1977년에 퇴학 처분을 받았다. 그 후 레닌그라드 기술전문학교에서 목공업을 공부하였으나, 적성에 맞지 않아 또 중퇴하였다(). 그러나 그는 이럼에도 불구하고 계속 록 음악에 열성적으로 참여한다. 이 시기에 이르러 그는 보일러 수리공으로 일을 하면서 파티 등의 장소에서 자신이 만든 곡을 연주하기 시작한다. 그러던 중 한 연주를 록 그룹 아쿠아리움의 멤버였던 보리스 그레벤시코프가 보게 되어, 그레벤시코프의 도움으로 그는 자신의 밴드를 시작하게 된다.\\n데뷔 초기.\\n레닌그라드의 록 클럽은 록 밴드들이 연주할 수 있던 소수 장소에 속했다. 이곳의 연중 록 콘서트에서 빅토르 초이는 처음 무대에 데뷔하게 된다. 그는 두 명의 아쿠아리움의 멤버들이 연주를 맡은 가운데 솔로로 연주한다. 그의 혁신적인 가사와 음악은 청중을 사로잡았다. 그가 유명해지기 전에 그는 음악하는 사람들이 도전하려고 하지 않는다고 말했다. 그는 아무도 하지 않았던 새로운 것을 창조하기 위해 실험적으로 가사와 음악을 만들었다. 이런 시도는 성공을 거두고, 데뷰이후 얼마 지나지 않아 멤버들을 모아 키노(러시아어로 영화, 극장이라는 뜻이다)를 결성한다. 그들은 빅토르 초이의 아파트에서 데모 테이프를 만들고, 이 테입은 처음엔 레닌그라드, 그리고 나중에는 전국의 록 매니아들에게 퍼지게 된다.\\n데뷔 이후.\\n1982년 키노는 첫 앨범인 45(소로크 피아트; 러시아어로 45라는 뜻)를 발표한다. 이 앨범의 이름이 45로 정해진 것은, 이 앨범의 재생시간이 총 45분이었기 때문이다. (후에 46(쏘록 쉐스찌)라는 앨범도 냈다.) 이 앨범에서 빅토르 초이는 음악에 정치적 목소리를 내려는 의지를 내비친다. \"엘렉트리치카(Elektrichka, 소련의 광역 전철)\"이란 노래는 원치 않은 곳으로 가는 전차에 끼여 끌려가고 있는 사람의 이야기를 다룬다. 이런 가사는 분명히 당시의 소련에서의 삶을 은유한 것이었으며, 이 노래는 공연이 금지된다. 이 노래의 메시지로 노래는 반항운동을 하던 젊은이들 사이에 유명해지며 키노와 빅토르 초이는 그들의 우상으로 떠오른다. 제2회 레닌그라드 록 클럽 콘서트에서 키노는 자신의 정치색을 더욱 분명히 드러낸다. 키노는 빅토르 초이의 반전음악 작품인 \"내 집을 비핵화지대로 선포한다.\"으로 1등을 차지하고, 이 노래는 당시 수만의 소련 젊은이들의 목숨을 빼앗고 있던 소련의 아프가니스탄 침공으로 더욱 더 유명해진다.\\n전성기.\\n1987년은 키노의 해였다. 7집 앨범 《혈액형(Gruppa krovi)》은 \"키노마니아\"로까지 불리는 사회현상을 불러일으킨다. 글라스노스트로 조금 더 개방적이 된 정치상황은 그의 가장 정치색이 짙은 앨범인 \"혈액형\"을 만들 수 있게 했다. 그러나 앨범의 메시지만이 청중을 사로잡은 것이 아니었고, 앨범에 담긴 음악 또한 이전에는 듣지 못하던 것이었다. 대부분의 곡은 소련의 젊은이들을 향한 외침이었으며, 능동적으로 나가서 국가를 변화시키라고 호소했다. 몇 개의 노래는 소련을 옥죄고 있던 사회문제들을 다루고 있다. 이 앨범은 빅토르 초이와 키노를 러시아 젊은이들의 영웅으로 등극시켰다. 1988년에는 영화 《이글라》의 주연으로 영화배우 데뷔를 하기도 하였다. 이후 몇 년간 그는 몇 편의 성공적인 영화를 찍었으며 영화제에 그의 영화를 홍보하기 위해 미국을 다녀오기도 했다.\\n이후 몇 개의 앨범이 더 나왔으며, 대부분이 정치적 메시지를 담았으며 밴드는 인기를 유지했다. 그는 당시 소련 젊은이 모두의 우상이었지만, 그런 것에 비하여 그는 소위 비교적 보통 수준의 삶을 살았다. 그는 계속 아파트 빌딩의 보일러 실에서 살며 일했다. 그는 자신의 직업을 즐기고 있으며 정부의 보조를 받지 못하고 있고, 자신들의 앨범은 공짜로 복제되어 퍼지기 때문에 밴드를 유지하기 위하여서라도 금액이 필요하다고 밝혔다. 이런 소박한 삶의 방식은 대중들이 그와 더욱 친밀감을 느끼기에 매우 충분했다.\\n갑작스러운 사망, 그리고 음모론.\\n1990년 키노는 모스크바의 레닌 스타디움에서 콘서트를 열어 6만 2천의 팬들을 모았다. 1990년 8월 14일 다음 앨범의 녹음을 마쳤으며, 레닌그라드에서 다른 멤버들이 녹음을 위해 기다리고 있었다. 그러나 8월 15일 아침 소련 라트비아 소비에트 사회주의 공화국 투쿰스에서 빅토르 초이가 운전하던 차가 마주오던 트럭과 충돌하였고 그 사고로 죽고 말았다. 그가 운전하였던 차는 형체를 알아볼 수 없도록 망가졌으며, 타이어 하나는 결국 찾지 못했다.\\n음모론에 따르면, KGB가 의도적으로 초이를 살해했다고 한다. 평소 반전과 평화 사상을 주장하던 초이가 러시아 권력자들의 눈 밖에 났다는 것이다. 실제로 트럭 기사가 종적을 감추고, 초이에게 유리한 목격자들의 증언이 기각되었으며(초이는 졸지도 운전 규칙을 어기지도 않았으며, 오히려 트럭 기사가 그에게 돌진했다는 사실), 시체가 봉인된 관에 담겨 서둘러 매장되었다는 사실 등 의문스러운 점이 한두 곳이 아니지만, 현재 러시아 경찰과 정부는 27년 동안 이 사안에 대해 철저히 침묵하고 있다.\\n1990년 8월 17일 소련의 유력 잡지인 콤소몰스카야 프라우다는 다음과 같이 그의 의미를 간추린다.\\n놀랍게도 교통사고에서 온전하게 건질 수 있었던 유일한 것은 다음 앨범에 쓰일 그의 목소리를 담은 테이프이었다. 목소리는 남은 멤버들의 나머지 녹음과 합쳐져 현재는 \"블랙 앨범\"으로 불리는 앨범으로 남아 있다. 이 유작 앨범은 밴드의 가장 인기있는 작품이며 러시아 록 역사에 있어서 키노의 자리를 확고하게 했으며, 빅토르 초이를 최고의 영웅이자 전설로 만들었다.\\n키노가 소비에트 음악과 사회에 미친 영향은 지대하다. 그들은 이전의 다른 어떤 그룹도 시도조차 하지 않았던 음악과 가사로 노래를 만들었다. 키노는 모던 러시아 록에게 문을 열어주었다. 키노는 아직도 러시아 전역에서 흔적을 남기고 있다. 레닌그라드 벽에는 그들에 대한 그라피티가 그려지고 있으며, 모스크바의 아르바트 가에는 한 벽 전체가 그들에게 헌정되었으며, 그곳에는 그를 기리기 위한 팬들이 모인다. 사망 10주기였던 2000년에는 러시아의 록 밴드들이 모여 빅토르 초이의 38번째 생일을 맞아 빅토르 초이의 헌정 음반을 만들었다.\\n최근.\\n2010년 8월 16일은 그의 20주기로써, 러시아 곳곳에서 추도식이 있었다고 보도되었다. 또한 2018년에는 그와 그 주변의 일대기를 다룬 영화인 《레토》가 개봉하였으며, 대한민국에는 2019년 1월 개봉하였다. 《레토》는 칸 영화제에서 사운드트랙 필름어워드 상을 수상하는 등 쾌거를 거두었으며, 감독 키릴 세레브렌니코프가 가택 연금 중 만든 작품이라는 특징이 있다.'}\n",
            "score: 9.55275 source:: {'id': '140', 'revid': '519225', 'url': 'https://ko.wikipedia.org/wiki?curid=140', 'title': '장국영', 'text': '장국영(, , , 1956년 9월 12일 ~ 2003년 4월 1일)은 홍콩의 배우이자 가수이다.\\n하카계 출신으로, 홍콩에서 출생하였으며 지난날 한때 중화인민공화국 광둥성 메이저우 시에서 잠시 유아기를 보낸 적이 있다. 그는 중산층 집안의 10남매중 막내로 태어나, 영국 북부의 리즈 대학교에서 섬유직물관리학을 공부했으나 결국 졸업하진 못했다. 홍콩으로 귀국후 우연히 나간 노래콘테스트에서 AMERICAN PIE를 불러 2위로 입상하여 데뷔하였다.\\n연기 활동.\\n1970년대에 홍콩 RTV (現 ATV/亞洲電視)에 가입, 《악어루 (鰐魚淚)》,《완화세검록 (浣花洗劍錄)》,《 (情人箭)》등에 출연했지만 평가는 전무했다. 그러다가 《영웅본색》, 《패왕별희》 등으로 아시아 권을 비롯한 세계에 이름을 날렸다.\\n오우삼의 《영웅본색》에서 저우룬파(주윤발)과 함께 주연을 함으로써 이 영화의 인기와 함께 한국에도 이름을 알리기 시작했다.\\n가수 활동.\\n1976년 홍콩 ATV의 Asian Music Contest에서 2등상을 수상. 가수 활동으로 슈퍼스타가 된 후 TV 브라운관으로 시작해서 영화와 가요계를 넘나들어 활동했다. 그러다 1990년 고별콘서트를 끝으로 가수 생활을 은퇴하고 캐나다에서 1년간 휴식 후 귀국하여 영화배우 활동에만 전념하였다. 그 후로 영화속 O.S.T.제작 등에 한하여 음악활동을 해오다 1995년 앨범 총애 (寵愛)를 발매함으로 다시 가수로 재개, 2000년까지 중화인민공화국, 일본, 싱가포르, 말레이시아 등 여러 아시아 지역에서 콘서트를 개최했다. 그러나 2000년에 가수 분야에서 다시 은퇴하고 2003년 사망할 때까지 영화배우 활동에만 전념하였다.\\n다음은 그의 앨범목록이다.\\n개인사.\\n《타임》지와의 인터뷰에서 양성애자라고 커밍아웃했다. 22세 쯤에 여배우 모순균과 교제했었으며, 1981년 영화 \"Agency 24\"를 촬영하면서 만난 여배우 예시배(倪詩蓓)와도 2년 동안 교제한 바 있다\\n1997년 콘서트에서 남자 애인 탕허더와 함께 나타났으며, 탕허더는 장국영이 죽을 때까지 관계를 지속했다.\\n사망.\\n2003년 4월 1일 홍콩 만다린 오리엔탈 호텔 24층에서 투신 자살했다. 향년 48세다. 그해 4월 5일 추도식에 많은 팬들이 SARS의 위험에도 불구하고 세계 곳곳에서 홍콩으로 찾아와 화제가 되기도 했다. 장국영이 죽은 4월 1일은 만우절이기 때문에 많은 사람들이 언론사들의 만우절 거짓말 이벤트라고 의심하기도 하였다.\\n자살 관련 논란.\\n홍콩 경찰은 장국영이 24층에서 투신하여 자살하였다고 밝혔는데 여러가지 부분에서 논란이 있으며 가장 유력한 용의자로 장국영의 전 재산 460억을 상속받은 애인 당학덕(탕허더, 통혹딱)이 지목된다.'}\n",
            "score: 6.497019 source:: {'id': '66', 'revid': '368112', 'url': 'https://ko.wikipedia.org/wiki?curid=66', 'title': '귄터 그라스', 'text': '귄터 그라스(, 1927년 10월 16일 ~ 2015년 4월 13일)는 독일의 소설가이자 극작가다.\\n생애.\\n독일 단치히 자유시(오늘날 폴란드의 그단스크)에서 식료품 상인이었던 독일계 아버지와 슬라브계 어머니 사이에서 태어났다. 하버드 대학에서 명예박사학위를 받았다. 1999년에 노벨 문학상을 수상하였다.\\n제2차 세계 대전과 그라스.\\n제2차 세계 대전 당시 독일 제국노동봉사대(RAD)에서 근무하던 중, 1944년에 무장친위대에 입대하여 10 SS기갑사단 프른즈베르크로 발령받아 참전했다. 징집당한 것이라는 얘기도 있으나, 당시 친위대의 독일인 대원들은 징집 대상이 아니라 자원 입대가 기본이었다(국방군 육군은 징병제였다). 종전후 부상당한 채 미군 포로로 잡혀 1946년까지 포로 수용소에 수감되었다. 이런 사실은 그라스 자신이 최근 발간한 자서전에서 인정했다.\\n전쟁 후의 그라스.\\n전후 1947~48년에는 광산에서 일하며 석공 기술 과정을 마친다. 이어 1948년부터 1952년까지는 뒤셀도르프 미술대학에서 그래픽과 조각을, 1953년부터 1956년까지는 베를린 예술대학에서 조각을 배웠다.\\n작품 활동.\\n1955년 슈투트가르트 방송국의 서정시 경연대회에 입상하고, 1956~57년에 예술 작품 전시와 별도로 작가 활동을 시작했다. 1958년까지 단문, 시, 희곡 등을 발표한다. 1954년에 결혼을 하고, 1960년부터 계속 베를린에 산다. 1959년에 매우 묘사적인 언어로 나중에 영화화 되기까지 한 《양철북》을 발표했다. 이 작품으로 그는 제2차 세계 대전 후 처음으로 세계 문학계에 이름을 날린 독일 작가가 된다. 이어 &lt;고양이와 쥐&gt; &lt;개의 해&gt;에서도 전쟁 전과 전쟁 후에 걸친 시대의 과오와 대결하고 있으며, 무대는 다같이 단치히이다. 이밖의 작품에 &lt;달팽이의 일기에서&gt; &lt;넙치&gt; 등이 있다. 1996년 유럽문화공로상을 받았다.\\n희곡.\\n그는 소설가로 활약하는 한편, 부조리극적인 소품(小品)인 &lt;요리사&gt; &lt;홍수&gt; &lt;버팔로까지 앞으로 10분&gt; 등을 발표한 바 있는데, 현대정치에도 직접 행동으로 참가하여 동·서 독일의 분열이라는 가장 현실적인 문제에 대담하게 도전한 &lt;천민의 폭동연습&gt;(1965)을 발표했다. 1953년 동독의 폭동 당시 브레히트를 모델로 하여 예술과 정치의 관련을 추구한 작품으로 &lt;독일의 비극&gt;이 있다.\\n사회 활동.\\n그라스는 전후 독일 사회민주당의 주요 지지자가 되어 외국인 혐오증, 신나치주의 등에 반대하는 사회활동에 적극 참여하였다.'}\n",
            "score: 4.380227 source:: {'id': '78', 'revid': '27964746', 'url': 'https://ko.wikipedia.org/wiki?curid=78', 'title': '히라가나', 'text': '히라가나(, )는 일본어에서 사용하는 두 가지 가나 중 하나이다. 가타카나는 주로 외래어 표기 등에 쓰이고, 히라가나는 다음과 같은 용도로 쓰인다.\\n히라가나는 여성이 많이 썼다고 한다. 그래서 온나데(; )라고 불린 적도 있다. 이런 이유로 히라가나는 여자들만 쓰는 글이라 하여, 오랫동안 일본의 공용 문서에선 가타카나와 한자(칸지)만이 사용되었다. 현재 일본 철도의 역명판에는 히라가나와 칸지가 적혀 있다. 히라가나는 헤이안 시대부터 쓰인 것으로 알려져 있다. 일본의 유아들도 가나를 배울 때는 히라가나를 먼저 배우고 가타카나를 나중에 배우기 때문에 유아용 그림책 등에는 가타카나로 쓰인 단어 위에 히라가나를 후리가나로 덧붙이기도 한다. 음절문자이다.\\n한영 자판 상태에서 히라가나를 입력할 경우 ㄸ+한자 키를 누르면 된다. 가타카나의 경우 장음 등 일부 문자를 제외하면, 꼭 ㅃ+한자 조합을 해야 한다.\\n역사.\\n히라가나는 만요가나에서 왔다.\\n메이지 시대 이전에는 히라가나의 모양이 확실히 정해지지 않고, 여러 형태의 문자가 사용되었다. 메이지 시대의 학제 시행 후에야 위와 같은 자형이 표준화되어 쓰이기 시작했다. 위 이외의 구식 자형은 헨타이가나(変体仮名)라고 부른다.'}\n",
            "score: 4.239711 source:: {'id': '99', 'revid': '525473', 'url': 'https://ko.wikipedia.org/wiki?curid=99', 'title': '공각기동대', 'text': '공각기동대(攻殻機動隊, Ghost in the Shell)는 시로 마사무네의 만화에서 만들어진 같은 세계관을 공유하는 한 무리의 작품들을 가리킨다. 공각기동대는 극장판 영화, 텔레비전 애니메이션, 소설, 비디오 게임 등 다양한 매체로 만들어졌다.'}\n",
            "score: 3.7317924 source:: {'id': '62', 'revid': '514184', 'url': 'https://ko.wikipedia.org/wiki?curid=62', 'title': '아오조라 문고', 'text': '아오조라 문고()는 ‘일본어판 구텐베르크 프로젝트’로 불리는 일본의 인터넷 전자도서관으로, 저작권이 풀린 문학작품을 수집, 전자문서화해서 인터넷에 공개하고 있다. 저자 사후 50년이 지난 메이지, 쇼와 시대 초기의 일본 문학 작품이 그 대부분을 차지하고 있고, 일본어 외 문학 작품의 일본어 번역 작품도 다수 있다. 1997년 2월 도미타 미치오, 노구치 에이치, 야마키 미에, 란무로 사테이 등 4명이 창설하여 시작되었다. 2016년 연간 방문객수는 940만 건 이상이다.\\n아오조라 문고에 수록된 작품은 JIS X 0208에 해당되는 한자 범위 내에서 자원봉사자에 의해 아오조라 문고 형식 텍스트파일이나 HTML 파일로 전자화된다. 또 아오조라 문고 수록파일 취급기준에 따라 자유롭게 이용할 수 있기 때문에, 수록된 작품을 PC는 물론 PDA와 휴대전화로도 볼 수 있다. 텍스트 파일을 큰 글자로 인쇄하거나 전용 소프트웨어에 불러들여 시각장애인용으로 이용하는 방안도 기대되고 있다. 아오조라 문고의 열람 소프트웨어는 따로 개발 및 제공되고 있는 것은 없지만, 전자사전이나 아이폰용 어플리케이션 등은 타사에서 개발하여 출시되어 있다.\\n개요.\\n저자 사망 이후 50년이 지나 저작권이 소멸한 메이지 시대부터 쇼와 시대 초기까지의 서적 대부분이 존재한다. 외국 번역작품이나 저자가 무료보기를 인정한 현대작품도 포함된다. 장르는 정치부터 취미까지 다양하지만, 비교적 문학작품(시대소설, 추리소설등의 오락작품 포함)이 많다. 유명작가의 작품이 모두 갖춰져있진 않지만 그래도 일본어작품에 관련해서는 충실하게 갖춰진 편이다. (번역작품의 경우 번역저작권을 문제로 수가 많지 않다.)\\n잘 알려지지 않은 작품을 보존, 소개하는 장점도 있다. 작품 텍스트화는 지금도 현재진행형이며 2011년 3월 15일 현재 등록작품수가 1만권이 넘었다.\\n고전작가인 모리 오가이, 나츠메 소세키, 아쿠타가와 류노스케, 최근의 작가로는 나카지마 아츠시, 다자이 오사무, 하야시 후미코, 미야모토 유리코, 호리 다쓰오, 사카구치 안고, 다카무라 고타로, 나가이 가후, 요시카와 에이지 등 인물의 작품이 있다.\\n운영.\\n아오조라 문고는 자원봉사로 운영되며 열람 역시 무료이다. 서비스 개시 초반에는 보이저 사에서 서버를 제공하였다. 1998년부터 1999년까지는 토미타가 작업 수칙과 매뉴얼을 만들었다.\\n자원봉사로 운영되기 때문에 작품의 입력과 교정 역시 자원봉사자가 한다. 입력은 원본을 보면서 타자입력이나 스캐너로 입력하는 방법으로 이뤄진다. 또 작품을 입력하는 \\'입력자\\'와 입력된 작품을 교정하는 \\'교정자\\'는 별도의 자원봉사자가 담당한다. 따라서 작품이 공개되기 전까지는 작품을 입력한 뒤 교정자가 교정을 예약할 때까지 \\'교정대기\\' (校正待ち)가 되고, 작업을 멈추게 된다. 즉, 입력하는 자원봉사자가 작품을 입력해 교정을 맡은 자원봉사자가 교정예약을 해서, 교정작업을 완료하기 전까지는 작품을 공개할 수 없다. 때문에 입력이 완료되어도 작업 상태가 \\'교정대기\\' 상태인 작품이 증가하고\\n있다. 이는 입력에 비해 교정 작업이 부족하기 때문으로, 아오조라 문고 출범 당시부터 안고 있는 문제점이기도 하다. 이 문제에 대해서는 작품의 교정작업을 하지 않고 공개하는 방안과 입력자가 교정한 것도 인정하자는 방안이 제기된 적이 있지만 현재까지도 이 방안은 채택되지 못하고 있다. 대신 2011년 12월 16일 공개분부터는 기부금을 재원으로 삼은 \\'유상교정\\' 서비스가 진행되고 있다.\\n2013년 8월 아오조라 문고의 설립자인 토미타가 사망한 것을 계기로, 아오조라 문고에 지속적인 지원을 해줄 \\'책의 미래 기금\\' (本の未来基金)이 설립됐다. 하지만 2015년부터는 엔지니어가 없는 상태로 서버를 강제로 돌리고 있으며, 서버 자체도 노후화되고 있다는 점이 문제되고 있다. 이 때문에 2015년 5월 \"\\'Code for 아오조라 문고\\' 아이디어 송\"이 개최되어 향후 시스템 운용에 대한 의견 교환이 이뤄졌다. 그 이후에는 해당 모임을 바탕으로 시스템 관리와 코드수정 등을 맡는 \\'aozorahack\\' 프로젝트가 진행되고 있다.\\n형식.\\n텍스트 파일을 아오조라 문고에 수록할 때, 텍스트 파일이 갖추어야 할 서식을 \\'아오조라 문고\\' 형식이라 부른다.\\n아오조라 문고 형식은 텍스트 파일로서 많은 환경에서 읽을 수 있도록 규격화되어있다. 때문에 가능한 한 원본의 충실한 재현을 목표로 삼고 있지만, 줄 바꿈이나 삽화 등의 정보는 원칙적으로 포함되지 않는다.\\n아오조라 문고 형식에 대응하는 텍스트 뷰어와 텍스트 편집기도 존재하며, 올림문자와 방점 등도 재현할 수 있다. 또 이러한 텍스트 뷰어에서는 본래 아오조라 문고 형식에 포함되지 않았던 삽화 정보를 삽입하거나 세로쓰기로 표시할 수 있으며, 텍스트를 읽기 쉽도록 만드는 다양한 기능이 포함되어 있다. 이러한 소프트웨어는 유료와 무료를 불문하고 종류가 다양하다.\\n올림문자.\\n일본어 표기에 많이 쓰이는 올림문자 (후리가나)는 그대로 올려쓰지 않고 \\'｜\\'나 \\'《》\\'로 표시한다. 올림문자를 《》 로 묶거나 ｜로 올릴 문자열을 특정하는 방식은 일본 시각장애인 독서지원협회 (BBA)의 원문입력 수칙에 따른 것이다.\\n이 같은 방식을 예시로 들자면 다음과 같다.\\n라고 표기했다면 \\'ぶんこ\\' (분코)라는 올림표기가 \\'文庫\\' 부분에 걸려 있는 것이다. 다만,\\n처럼 올림표기를 쓸 한자가 가나로 충분히 구분된다면 ｜를 써서 분리할 필요가 없으므로 쓰지 않는다. 또한,\\n처럼 가나에 올림표기를 강제로 쓰는 것도 가능하다.'}\n",
            "score: 2.6410937 source:: {'id': '38', 'revid': '585815', 'url': 'https://ko.wikipedia.org/wiki?curid=38', 'title': '백남준', 'text': '백남준(白南準, , 1932년 7월 20일 ~ 2006년 1월 29일)은 한국 태생의 세계적인 비디오 아트 예술가, 작곡가, 전위 예술가이다. 본관은 수원(水原)이고, 출신지는 서울이다.\\n생전에 뉴욕, 쾰른, 도쿄, 마이애미와 서울에 주로 거주한 그는 여러 가지 매체로 예술 활동을 하였다. 특히 비디오 아트라는 새로운 예술의 범주를 발전시켰다는 평가를 받는 예술가로서 \\'비디오 아트의 창시자\\'로 알려져 있다.\\n생애.\\n현 서울특별시 종로구 서린동 (구 일제 강점기 경기도 경성부 서린정) 출신이다. 친일파인 아버지 백낙승과 어머니 조종희 사이의 3남 2녀 중 막내로 태어났다. 그후 종로구 창신동 197번지 소위 \"큰대문집\"에서 18세까지 살았다. 수송국민학교와 경기제1고등보통학교를 다니면서 피아니스트 신재덕에게 피아노 연주를, 이건우에게 작곡을 각각 배웠다. 이때 한국이 낳은 작곡가 김순남을 사사했다. 1949년 그는 홍콩 로이덴 스쿨로 전학했으며, 한국 전쟁이 발발하기 이전 가족이 일본으로 이주했다. 그 후 일본으로 건너가 1952년 도쿄 대학교 문과부에 입학했다. 2년 후 미술사학 및 미학으로 전공을 정했지만, 실제로는 일본 당대의 작곡가 모로이 사부로, 미학자 노무라 요시오 등에게서 작곡과, 음악사학을 공부했다. 졸업 논문은 ‘아르놀트 쇤베르크 연구’이다.\\n1956년 백남준은 졸업과 함께 독일로 유학을 떠나 뮌헨 대학교 및 쾰른 대학교 등에서 서양의 건축, 음악사, 철학 등을 공부하였다. 뮌헨 대학교 입학 1년 후에는 프라이부르크 국립 음악 대학교로 옮겨 볼프강 포르트너 교수에게 배우지만, 곧 쇤베르크 이후 현대음악의 실험이 활발히 진행되던 다름슈타트 하기 강좌에 참여했다. 1958년 그 곳에서 현대음악가 존 케이지를 만나 그의 음악에 대한 파괴적 접근과 자유정신으로부터 깊은 영감을 얻었다. 이 영감은 \"세계의 역사는 우리에게 알려준다. 주어진 게임에서 이길 수 없다면 규칙을 바꿔라\" 라는 것으로 규정된다. 이후 1950년대부터 활발해지기 시작한 독일 라인 지역의 액션뮤직의 현장에서 백남준은 ‘아시아에서 온 문화테러리스트’(앨런 카프로)라고 불릴 정도의 탁월한 퍼포먼스 아티스트로 활약했다. 1959년 ‘존 케이지에게 보내는 경의’에서 음악적 콜라주와 함께 피아노를 부수는 퍼포먼스를 선보이는 것을 시작으로, 바이올린을 단숨에 파괴하거나(바이올린 솔로) 존 케이지가 착용한 넥타이를 잘라버리는 퍼포먼스(피아노 포르테를 위한 연습곡)가 특히 유명하다. 이 초기 퍼포먼스에 대해 백남준은 스스로 \"충격, 표현주의, 낭만주의, 클라이맥스, 놀라움, 기타 등등을 보여준 것\"이라고 표현한 바 있다. 1961년 카를하인츠 슈토크하우젠의 음악 퍼포먼스 ‘오리기날레’에서 머리와 넥타이로 잉크를 묻혀 두루마리에 흔적을 남기는 독특한 퍼포먼스 심플 머리를 위한 선율을 보여주기도 했다. 1960년대 초반 조지 마키우나스, 요셉 보이스 등과 의기투합하여 플럭서스 활동을 함께 전개했다. 다다이즘에 영향을 받은 플럭서스는 헤라클레이투스가 주장한 ‘변화 생성의 흐름’ 이라는 개념을 받아들여 \"목적이 없는 자유, 실험을 위한 실험\"이라는 명목 하에 이벤트와 퍼포먼스 그리고 전위음악에 주력했고, 곧 유럽과 아시아 및 미국 등 세계로 퍼져나갔다.\\n1961년 백남준은 작곡가 슈토크하우젠이 중심이 된 쾰른의 WDR 전자음악 스튜디오에 출입했으며, 이때 1950년대부터 노버트 위너에 의해 제안된 \\'사이버네틱스\\' 개념 하에서 전자공학을 공부한 것으로 알려져 있다. 특히 레이다와 TV 작업에 몰두했던 독일 작가 칼 오토 괴츠의 실패를 거울 삼아서 2년여 동안 홀로 TV를 활용한 미디어 아트로서의 가능성을 탐문하고 실험했다. 그 성과를 바탕으로 1963년 독일 부퍼탈 파르나스 갤러리에서 자신의 첫 번째 전시 ‘음악의 전시-전자 텔레비전’을 열었으며, 13대의 실험적인 TV를 통해 훗날 비디오 아트라고 불리게 되는 초기 형태를 보여주었다. 이 전시는 백남준이 자신의 즉흥음악 또는 무음악의 발상에 기초한 실제 퍼포먼스, 그 흔적과 결과물처럼 유럽에서 자신이 진행해온 작업의 성과와 함께 TV를 비롯한 미디어로 새로운 예술의 형태를 시도하는 작업이 공존하고 있었다. ‘적분된 피아노’, ‘랜덤 액세스 뮤직’, ‘레코드 샤슐릭’같은 20세기 전위음악에 젖줄을 대고 있는 실험적 음악의 시도와 ‘잘린 소머리’, ‘파괴된 누드 마네킹’, ‘보이스의 피아노 파괴 퍼포먼스’\\'걸음을 위한 선\\' \\'바람을 위한 선\\' 같은 우상파괴적 설치 작업 및 참여예술 형태의 퍼포먼스가 함께 펼쳐졌다. 청년 백남준은 이러한 전시 내용을 ‘동시성’, ‘참여’, ‘임의접속’ 등등에 관한 16개의 테마로써 정리하는 종합적인 큐레이팅 전시로 보여주었기 때문에 최근 독일, 오스트리아 등지의 연구자들 사이에서 이 전시의 중요성을 재평가하면서 아카이빙 작업과 연구가 점차 활발해지는 추세에 있다.\\n1964년 백남준은 일본으로 건너가 \\'로봇 K-456\\'을 제작했으며, 곧 세계 예술의 중심지 뉴욕으로 이주했다. 뉴욕 언더그라운드 필름 운동의 중심지 중 하나였던 시네마테크 필름메이커스에 관여했으며, 스스로 영상 작업을 진행하기도 했다. 1965년 소니의 포타팩(세계 최초의 휴대용 비디오카메라)으로 미국 뉴욕을 첫 방문 중이던 교황 요한 바오로 6세를 촬영하여 곧바로 그 영상을 ‘카페 오 고고’에서 방영했다. 이것이 미술사에서는 한동안 공식적인 비디오 아트의 시작으로 기록되어 있었다. 지금은 1963년 첫번째 전시를 비디오아트의 기점으로 보고 있다. 또한 첼로 연주자이자 뉴욕 아방가르드 페스티벌의 기획자였던 샬럿 무어먼과 함께 비디오 아트와 음악을 혼합한 퍼포먼스 작업을 활발히 펼쳤다. 특히 1967년 음악에 성적인 코드를 집어넣은 백남준의 ‘오페라 섹스트로니크’에서 샬럿 무어먼은 누드 상태의 첼로 연주를 시도하다가 뉴욕 경찰에 체포되어 큰 사회적 파장을 불러일으켰다. 그 결과로 인해 예술 현장에서 누드를 처벌할 수 없다는 뉴욕의 법 개정이 이루어지는 획기적인 진전이 일어난다. 이후에도 미디어 아트가 미국 뉴욕을 중심으로 서서히 득세해가는 시대적 조류 속에서 두 사람은 ‘살아있는 조각을 위한 TV 브라’, ‘TV 첼로’, ‘TV 침대’ 등등 미디어 테크놀로지와 퍼포먼스를 결합한 많은 예술활동을 전개했다.\\n1974년부터 백남준은 영상으로서의 비디오 아트를 새로운 미술적 방법인 설치 미술로 변환하여 다양하게 진행했으며, 그에 따라 ‘TV 붓다’, ‘달은 가장 오래된 TV다’, ‘TV 정원’, ‘TV 물고기’ 등등 많은 대표작을 선보였다. 이 작품들은 비디오 아트와 생명의 상징을 전자적으로 결합하여 테크놀로지로 물든 현대 사회의 새로운 합성적 생명력을 추구했다는 평판을 얻었다. 특히 \\'TV 붓다\\'는 그의 초기 비디오 설치의 경향을 잘 보여주는 대표작으로서 가장 널리 알려졌다. 1960년대 후반부터 미국의 문화적 환경이 미디어 테크놀로지에 호의적으로 변화하면서 폭발적인 수준의 미디어 전시가 빈발했고, 백남준의 비디오 아트는 그룹전 형태로 수많은 전시에 활발하게 참여했다. 1974년 뉴욕 에버슨 미술관 개인전과 함께 이라는 예술과 기술을 교차시키는 하이브리드에 관한 저작을 내놓아 미디아 아트의 이해를 도왔으며, 1982년 뉴욕 휘트니 미술관에서 개최된 ‘백남준 회고전’을 통해 그의 예술 세계가 뉴욕을 중심으로 미국 사회에 많이 알려지는 계기가 되었다.\\n1970년대 중반부터는 뉴욕 WNET 방송국, 보스턴 WGBH 방송국과 협력하여 자신의 비디오 아트를 공중파 TV에서 방송했고, 이는 네트워크 방송을 끌어들여 예술 세계의 영역 확장을 꾀한 놀라운 시도였다. 나아가 1984년 1월 1일 ‘굿모닝 미스터 오웰’은 세계적인 아티스트들의 퍼포먼스를 뉴욕 WNET 방송국과 파리 퐁피두 센터를 연결한 실시간 위성 생중계로 방송하여 전 세계적 반향을 불러일으켰다. 샌프란시스코와 서울까지 연결된 이 국제적인 규모의 위성 아트에는 로리 앤더슨, 피터 가브리엘, 오잉고 보잉고, 존 케이지, 요셉 보이스, 앨런 긴즈버그, 이브 몽탕 등의 예술가과 대중문화의 스타가 다수 참여했으며, 전 세계 2천 5백만명(재방송 포함)이 시청하였다. 이로써 전세계적인 차원의 대중적 각인이 이루어졌고, 마치 대중스타처럼 성가를 높였다. 이후에도 ‘위성 아트’ 3부작으로 명명된 ‘바이 바이 키플링’(1986), ‘손에 손잡고’(1988) 등이 이어져 위성 연결을 통한 전세계의 네트워크가 어떻게 새로운 부족사회를 낳는지 실감시켰다.\\n1984년 일본 도쿄 소게쓰[草月]홀에서 백남준과 요셉 보이스가 공동으로 참여한 퍼포먼스 \\'코요테 콘서트 II\\'가 펼쳐졌으며, 이들이 각각 몽골의 늑대 울음소리와 초원의 달빛을 음악적으로 표현한 것을 통해 1961년 첫 만남부터 계속 이어온 공동의 관심사가 무엇인지 알려지기 시작했다. 그러나 이들의 이후 퍼포먼스 계획은 요셉 보이스의 죽음과 함께 미완으로 끝났다.\\n1992년 \\'비디오 때, 비디오 땅\\' 전시는 독일 쿤스트 할레와 스위스 쮜리히에서 진행된 전시의 서울 투어전시로서 당시 과천 막계동에 자리잡은 지 몇 년 되지 않았던 국립현대미술관 과천관에 총 관람 인원 20만명이 찾은 첫번째 전시로 기록되었다. 이 전시의 주요한 작품은 \\'나의 파우스트\\' 시리즈이다. 1993년 백남준은 독일 작가 한스 하케와 함께 베니스 비엔날레 독일관 작가로 초대되어 국가전시관 부문에서 황금사자상을 수상했다. \\'문명의 동서남북\\'이라는 주제의 이 전시에서 그는 북방 유라시아의 유목 문화를 배경으로 전자적 소통을 시도하는 비디오 로봇 형태의‘칭기스칸의 복권’, ‘마르크폴로’, ‘훈족의 왕 아틸라’,‘스키타이의 왕 단군’, ‘로봇 전사’, ‘고대기마인물상’ 같은 작품들을 중심으로 다수의 작품을 내놓았다.\\n1995년 백남준은 제1회 광주 비엔날레 태동의 산파 역할을 하며, 한국 미술이 국제적으로 진출할 수 있도록 조력자 역할을 수행했다. 제1회 광주 비엔날레는 국내외 총 관람객이 160만 명에 달하는 성공을 거두었고, 특히 백남준이 직접 관여한 ‘INFO Art’전이 주목받았다. 또한 백남준은 같은 해 베니스 비엔날레 국가전시관 부문에 한국관을 설치하는 일에 결정적인 역할을 했다. 이로써 한국 미술이 세계 미술계에 진출하는 교두보가 마련되었다고 하겠다. 같은 해 그의 예술적 정수가 담긴 일렉트로닉 수퍼하이웨이 전시를 진행했다. 1996년 4월 9일 뇌졸중으로 쓰러졌으며, 6개월만인 그해 10월에 재기했다. 2000년 뉴욕 구겐하임 미술관에서 ‘백남준의 세계’ 라는 대규모 회고전이 열렸으며, 이때 백남준은 레이저 아트 ‘야곱의 사다리’, ‘삼원소’ 등을 전시한 바 있다.\\n2006년 1월 29일, 미국 마이애미의 자택에서 노환으로 75세로 별세, 유해가 서울, 뉴욕, 독일에 나눠서 안치되었다.'}\n",
            "score: 2.2604992 source:: {'id': '171', 'revid': '29136357', 'url': 'https://ko.wikipedia.org/wiki?curid=171', 'title': '로봇', 'text': '로봇(, )은 인간과 유사한 모습과 기능을 가진 기계 또는 한 개의 컴퓨터 프로그램으로 작동할 수 있고(programmable), 자동적으로 복잡한 일련의 작업(complex series of actions)을 수행하는 기계적 장치를 말한다. 또한 제조공장에서 조립, 용접, 핸들링 등을 수행하는 자동화된 로봇을 산업용 로봇이라 하고, 환경을 인식하고 스스로 판단하는 기능을 가진 로봇을 \\'지능형 로봇\\'이라 부른다. 사람과 닮은 모습을 한 로봇을 \\'안드로이드\\'라 부르기도 한다. 그리고 다른 뜻은 형태가 있으며, 자신이 생각할 수 있는 능력을 가진 기계라고도 한다. 그리고 인공의 동력을 사용하는 로봇은 사람 대신, 또는 사람과 함께 일을 하기도 한다. 통상 로봇은 제작자가 계획한 일을 하도록 설계된다. 로봇\\'이란 용어는 체코슬로바키아의 극작가 카렐 차페크(Carel Čapek)가 1920년에 발표한 희곡 \"R.U.R\"에 쓴 것이 퍼져 일반적으로 사용되게 되었다. 또한 로봇의 어원은 체코어로 \"노동\"을 의미하는 \"Robota\"이다.\\n어원 및 정의.\\n어원.\\nRobot이라는 말은 1920년 체코슬로바키아의 극작가 카렐 차페크(Karel Čapek)의 희곡 R.U.R.(Rosuum\\' s Universal Robots)에서 처음 사용되었다. 로봇의 어원은 체코어의 노동을 의미하는 단어 \\'robota\\'에서 나왔다고 알려지고 있다. 차페크는 R.U.R.에서 모든 작업능력에서 인간과 동등하거나 그 이상이면서 인간적 “감정”이나 “혼”을 가지고 있지 않은 로봇이라고 불리는 인조인간을 등장시키고 있다. 로봇은 언젠가 쇠조각으로 변하여 반항하는 정신을 발달시킴으로써 자신들의 창조주인 인간을 전부 죽여 버린다고 하는 비극을 인상적으로 나타내고 있다.\\n로보틱스(Robotics)라는 말은 로봇의 활용과 로봇 공학을 의미한다. 이 말은 미국 과학자이면서 작가인 아이작 아시모프(Issac Asimov; 1920년 1월 2일 ~ 1992년 4월 6일)가 1942년에 발간한 단편 Runaround에서 최초로 사용하였다.\\n정의.\\n명사로서 로봇(robot)은 다음의 의미를 지닌다.\\n카렐 차페크.\\n일할 수 있는 능력은 있어도 생각할 수 있는 능력이 없는 인간을 닮은 것.\\n로봇의 3원칙.\\n본문|로봇공학의 삼원칙\\n아이작 아시모프가 1950년 발간한 소설인 \\'I\\'Robot\\'에서 제안된 로봇의 행동에 관한 3가지 원칙이다.\\n제1법칙:로봇은 인간에게 해를 끼쳐서는 안 되며, 위험에 처해 있는 인간을 방관해서도 안 된다.\\n제2법칙:로봇은 인간의 명령에 반드시 복종해야만 한다. 단, 제1법칙을 거스를 경우에는 제외다.\\n제3법칙:로봇은 자기 자신을 보호해야만 한다. 단, 제1법칙과 제2법칙을 걸러버릴경우는 예외다.\\n군사용 로봇이 공격의 기능을 갖출 경우, 첫 번째 원칙에 위배되게 된다.\\n하지만 3원칙만 듣게되면 만약 예시로 로봇에게 지구에 있는 나무를 다 없애주라고 할때 나무를 없애는것이기때문에 실행을 할 수가 있어 인간에게 위험할수있다. 그래서 몇몇사람들은 이를 바꾸려고한다.\\n로봇의 이용.\\n그동안 인간이 해 오던 많은 일들을 지금은 로봇이 대신하고 있다. 산업 현장에는 단조로운 반복 작업이나 따분한 작업, 불쾌한 작업들이 많은데, 이와 같은 작업은 특히 로봇에게 맡기기에 적합하다. 조립 공장에서 리벳 박는 일, 용접, 자동차 차체를 칠하는 일 등은 그 좋은 예이다. 이런 종류의 작업은 로봇 쪽이 인간보다 더 잘 해낼 수 있다. 왜냐하면 로봇은 언제나 일정한 수준의 정밀도와 정확도로 작업을 계속할 수 있으며, 결코 지칠 줄 모르기 때문이다. 따라서 제품의 품질은 항상 일정하며 게다가 휴식을 취할 필요가 없기 때문에 많은 양의 제품을 만들 수 있다.\\n또한 로봇은 위험한 작업을 대신할 수가 있다. 방호복을 입지 않고 원자력 공장에서 방사성 물질을 취급하거나, 유독 화학 물질을 취급할 수가 있으며, 인간에게는 너무 덥거나 추운 환경에서도 일할 수가 있다. 인간의 생명이 위험에 노출될 수 있는 곳에서도 로봇을 사용할 수 있다. 예를 들면 폭발물을 수색하거나 폭탄의 뇌관을 제거하는 일, 그리고 우주 공간에서의 작업도 그중의 하나이다.\\n로봇은 우주 공간에서의 작업에 특히 이상적이다. 지구를 돌고 있는 인공위성을 수리하거나 유지하는 데 사용되기도 하고, 보이저호와 같이 탐사와 발견을 목적으로 먼 천체까지 비행하는 데도 로봇이 사용된다.\\n한편 가정에서도 점점 많은 로봇이 가사를 돕기 위해 사용되고 있다. 그리고 육체적인 장애를 가진 사람들을 돌보는 일에도 많이 이용될 것으로 기대된다. 로봇 간호보조자는 장애자나 노령으로 인해 체력이 약해진 사람들이 가족들에게서 독립하여 혼자서도 살 수 있도록 해주며, 병원에 입원하지 않아도 될 수 있도록 도와 주게 될 것이다.\\n로봇이 사용되는 분야의 예를 들면 다음과 같다.\\n산업 및 의료용.\\n주로 힘이나 정밀도를 요하는 작업 담당\\n수치 제어 공작 기계.\\n공장에서 제품을 생산할 때 컴퓨터를 이용하면, 제품의 생산 계획이나 설계·제조·보관·출고에 이르기까지 거의 모든 일을 처리할 수 있다. 기계 공업에서 가장 많이 사용하는 공작 기계는 금속 등을 가공할 때 사용된다. 과거에는 이 기계를 사용하기 위해 고도의 숙련된 기술이 필요했다. 그러나 최근에는 수치 제어 공작 기계가 개발되어 기술이 없어도 금속을 가공할 수 있게 되었다. 수치 제어 공작 기계는 가공하는 작업의 순서와 내용을 수치 정보로 만들어 기계에 입력시키면 기계가 자동적으로 가공 작업을 하는 것이다. 이 수치 제어 공작 기계와 자료의 입력 관리를 맡는 컴퓨터가 결합하여 만들어진 것이 컴퓨터 수치 제어 공작 기계이다. 이 수치 제어 기계에서 더 발전하여 복잡한 가공을 할 수 있도록 만든 장치가 공작 로봇이다.\\n가정용.\\n주로 인내심을 요하는 작업 담당\\n군사 및 탐사용.\\n주로 위험한 환경에서의 작업 담당\\n각국의 로봇.\\n미국.\\n미국에서는 로봇이 생활에 도움을 주는 기계라기보다 앞으로 인류를 위협할지도 모른다는 생각이 있어서 주로 터미네이터 등 영화에서 로봇이 인류를 위협하는 존재로 나와 있다. 또 무인 조종 비행기 등 군사에서 쓰는 군사 로봇이 가장 잘 발달되어 있다.\\n2015년, 미국의 로봇 제조사인 한슨 로보틱스(Hanson Robotics)에서 일상을 위한 최신 인공지능 로봇 , \\'한(Han)\\'을 공개하였다. 한은 사람과 대화를 할 수 있는 건 물론, 사람의 표정, 성, 나이 등을 캐치할 수 있다. 한의 가장 놀라운 점은 인간같은 표정을 지을 수 있다는 것이다.\\n일본.\\n일본 에도 시대에는 가라쿠리 인형 같은 로봇이 있었다. 일본은 아시모등과 같은 휴머노이드형 로봇이나 소니의 AIBO와 같은 애완용 로봇 그리고 산업용 로봇 외에도 인간의 모습에 가까운 로봇 개발에 힘쓰고 있다. 아톰, 건담 같은 로봇 애니메이션이 대중적인 인기를 얻고 있다.\\n중국.\\n중국에서는 로봇을 산업이나 가정에 도움을 주는 기계라보다는 사람이 조종하는 꼭두각시라고 생각한다. 그러나 중국은 미국과 일본, 심지어는 대한민국까지도 로봇공학에 힘을 쏟고 있다는 것을 인식하자 이들에게 뒤떨어지지 않기 위해 2000년에 선행자(先行者)라는 이름의 직립보행형 로봇을 개발하기도 했으나 선행자의 양 다리 사이에 설치된 파이프 모양의 부속으로 인하여 일본에서 \\'최종중화병기 선행자\\'라는 애니메이션이 발표되는 등 개그캐릭터로서 폭발적인 인기를 끌기도 했다.\\n한국.\\n조선시대에 물의 힘으로 여러 인형이 작동하는 물시계 자격루와 옥루를 제작하였다. 한국은 초기에는 산업과 경제에 필요한 기계를 제작하였고, 근래에 들어서는 휴머노이드형 로봇 개발에 힘쓰고 있다. 로봇은 산업 뿐만 아니라 대회에서 인간을 대신하여 겨루는 용도로도 제작되고 있다. 또한 물리적인 움직임 없이 사람과 의사소통하며 감정을 교류하는 소셜 로봇도 있다. 예를 들면, 2015년 5월 글로벌 크라우드 펀딩 사이트인 인디고고(Indiegogo)를 통해 처음으로 세상에 소개된 뮤지오가 있다.'}\n",
            "score: 1.896611 source:: {'id': '9', 'revid': '235869', 'url': 'https://ko.wikipedia.org/wiki?curid=9', 'title': '수학', 'text': '수학(數學, )은 수, 양, 구조, 공간, 변화 등의 개념을 다루는 학문이다. 널리 받아들여지는 명확한 정의는 없으나 현대 수학은 일반적으로 엄밀한 논리에 근거하여 추상적 대상을 탐구하며, 이는 규칙의 발견과 문제의 제시 및 해결의 과정으로 이루어진다. 수학은 그 발전 과정에 있어서 철학, 과학과 깊은 연관을 맺고 있으며, 다만 엄밀한 논리와 특유의 추상성, 보편성에 의해 다른 학문들과 구별된다. 특히 수학은 과학의 여느 분야들과는 달리 자연계에서 관측되지 않는 개념들에 대해서까지 이론을 추상화시키는 특징을 보이는데, 수학자들은 그러한 개념들에 대한 추측을 제시하고 적절하게 선택된 정의와 공리로부터 엄밀한 연역을 거쳐 그 진위를 파악한다.\\n수학의 개념들은 기원전 600년 경에 활동하며 최초의 수학자로도 여겨지는 탈레스의 기록은 물론, 다른 고대 문명들에서도 찾아볼 수 있으며 인류의 문명과 함께 발전해왔다. 오늘날 수학은 자연과학, 사회과학, 공학, 의학 등 다른 여러 학문에서도 핵심적인 역할을 하며 다양한 방식으로 응용된다.\\n수학을 의미하는 \\'mathematics\\'라는 단어는, \\'아는 모든 것\\', \\'배우는 모든 것\\'이라는 뜻의 고대 그리스어 \\'máthēma\\'(μάθημα) 및 그 활용형 mathēmatikós(μαθηματικός)에서 유래되었다.\\n역사.\\n역사적으로 고대부터 현대에 이르기까지 문명에 필수적인 건축, 천문학, 정치, 상업 등에 수학적 개념들이 응용되어 왔다. 교역·분배·과세 등 인류의 사회 생활에 필요한 모든 계산에 수학이 관여해 왔고, 농경 생활에 필수적인 천문 관측과 달력의 제정, 토지의 측량 또한 수학이 직접적으로 사용된 분야이다. 고대 수학을 크게 발전시킨 문명으로는 이집트, 인도, 중국, 그리스 등이 있다.\\n특히 고대 그리스 문명에서는 처음으로 방정식에서 변수를 문자로 쓰는 등 추상화가 발전하였고 유클리드의 원론에서는 최초로 엄밀한 논증에 근거한 수학이 나타난다. 수학의 발전은 이후로도 계속되어 16세기의 르네상스에 이르러서는 과학적 방법과의 상호 작용을 통해 수학과 자연과학에 있어서 혁명적인 연구들이 진척되었고, 이는 인류 문명 발달에 큰 영향을 미치게 되었다.\\n세부 분야.\\n수학의 각 분야들은 상업에 필요한 계산을 하기 위해, 숫자들의 관계를 이해하기 위해, 토지를 측량하기 위해, 그리고 천문학적 사건들을 예견하기 위해 발전되어왔다. 이 네 가지 목적은 대략적으로 수학이 다루는 대상인 양, 구조, 공간 및 변화에 대응되며, 이들을 다루는 수학의 분야를 각각 산술, 대수학, 기하학, 해석학이라 한다. 또한 이 밖에도 근대 이후에 나타난 수학기초론과 이산수학 및 응용수학 등이 있다.\\n산술.\\n산술은 자연수와 정수 및 이에 대한 사칙연산에 대한 연구로서 시작했다. 수론은 이런 주제들을 보다 깊게 다루는 학문으로, 그 결과로는 페르마의 마지막 정리 등이 유명하다. 또한 쌍둥이 소수 추측과 골드바흐 추측 등을 비롯해 오랜 세월 동안 해결되지 않고 남아있는 문제들도 여럿 있다.\\n수의 체계가 보다 발전하면서, 정수의 집합을 유리수의 집합의 부분집합으로 여기게 되었다. 또한 유리수의 집합은 실수의 집합의 부분집합이며, 이는 또다시 복소수 집합의 일부분으로 볼 수 있다. 여기에서 더 나아가면 사원수와 팔원수 등의 개념을 생각할 수도 있다. 이와는 약간 다른 방향으로, 자연수를 무한대까지 세어나간다는 개념을 형식화하여 순서수의 개념을 얻으며, 집합의 크기 비교를 이용하여 무한대를 다루기 위한 또다른 방법으로는 기수의 개념도 있다.\\n대수학.\\n수 대신 문자를 써서 문제해결을 쉽게 하는 것과, 마찬가지로 수학적 법칙을 일반적이고 간명하게 나타내는 것을 포함한다. 고전대수학은 대수방정식 및 연립방정식의 해법에서 시작하여 군, 환, 체 등의 추상대수학을 거쳐 현대에 와서는 대수계의 구조를 보는 것을 중심으로 하는 선형대수학으로 전개되었다. 수의 집합이나 함수와 같은 많은 수학적 대상들은 내재적인 구조를 보인다. 이러한 대상들의 구조적 특성들이 군론, 환론, 체론 그리고 그 외의 수많은 대수적 구조들을 연구하면서 다루어지며, 그것들 하나하나가 내재적 구조를 지닌 수학적 대상이다. 이 분야에서 중요한 개념은 벡터, 벡터 공간으로의 일반화, 그리고 선형대수학에서의 지식들이다. 벡터의 연구에는 산술, 대수, 기하라는 수학의 중요한 세개의 분야가 조합되어 있다. 벡터 미적분학은 여기에 해석학의 영역이 추가된다. 텐서 미적분학은 대칭성과 회전축의 영향 아래에서 벡터의 움직임을 연구한다. 눈금없는 자와 컴퍼스와 관련된 많은 고대의 미해결 문제들이 갈루아 이론을 사용하여 비로소 해결되었다.\\n기하학.\\n공간에 대한 연구는 기하학에서 시작되었고, 특히 유클리드 기하학에서 비롯되었다. 삼각법은 공간과 수들을 결합하였고, 잘 알려진 피타고라스의 정리를 포함한다. 현대에 와서 공간에 대한 연구는, 이러한 개념들은 더 높은 차원의 기하학을 다루기 위해 비유클리드 기하학(상대성이론에서 핵심적인 역할을 함)과 위상수학으로 일반화되었다. 수론과 공간에 대한 이해는 모두 해석 기하학, 미분기하학, 대수기하학에 중요한 역할을 한다. 리 군도 공간과 구조, 변화를 다루는데 사용된다. 위상수학은 20세기 수학의 다양한 지류속에서 괄목할만한 성장을 한 분야이며, 푸앵카레 추측과 인간에 의해서 증명되지 못하고 오직 컴퓨터로만 증명된 4색정리를 포함한다.\\n해석학.\\n변화에 대한 이해와 묘사는 자연과학에 있어서 일반적인 주제이며, 미적분학은 변화를 탐구하는 강력한 도구로서 발전되었다. 함수는 변화하는 양을 묘사함에 있어서 중추적인 개념으로써 떠오르게 된다. 실수와 실변수로 구성된 함수의 엄밀한 탐구가 실해석학이라는 분야로 알려지게 되었고, 복소수에 대한 이와 같은 탐구 분야는 복소해석학이라고 한다. 함수해석학은 함수의 공간(특히 무한차원)의 탐구에 주목한다. 함수해석학의 많은 응용분야 중 하나가 양자역학이다. 많은 문제들이 자연스럽게 양과 그 양의 변화율의 관계로 귀착되고, 이러한 문제들이 미분방정식으로 다루어진다. 자연의 많은 현상들이 동역학계로 기술될 수 있다. 혼돈 이론은 이러한 예측 불가능한 현상을 탐구하는 데 상당한 기여를 한다.\\n수학기초론 관련 분야.\\n수학의 기초를 확실히 세우기 위해, 수리논리학과 집합론이 발전하였고, 이와 더불어 범주론이 최근에도 발전되고 있다. “근본 위기”라는 말은 대략 1900년에서 1930년 사이에 일어난, 수학의 엄밀한 기초에 대한 탐구를 상징적으로 보여주는 말이다. 수학의 엄밀한 기초에 대한 몇 가지 의견 불일치는 오늘날에도 계속되고 있다. 수학의 기초에 대한 위기는 그 당시 수많은 논쟁에 의해 촉발되었으며, 그 논쟁에는 칸토어의 집합론과 브라우어-힐베르트 논쟁이 포함되었다.\\n영향.\\n오늘날 수학은 자연과학, 공학뿐만 아니라, 경제학 등의 사회과학에서도 중요한 도구로 사용된다. 예를들어, 정도의 차이는 있으나, 미적분학과 선형대수학은 자연과학과 공학, 경제학을 하는데에 필수적 과목으로 여겨지며, 확률론은 계량경제학에 응용된다. 통계학은 사회과학 이론에 근거를 마련하는데 필수적이다. 16세기에 갈릴레오 갈릴레이가 \"자연이라는 책은 수학이라는 언어로 기록되어 있다.\"는 주장과 함께 물리학에 수학적 방법을 도입하였고, 17세기에 아이작 뉴턴이 고전 역학의 기본 물리학 법칙들을 수학적으로 기술하고 정립하여 물리학 이론에서 수학적 모델링은 필수적 요소가 되었다. 또한 이 시기는 과학적 방법이 정립되는 시기이기도 한데, 많은 과학적 현상들이 수학적 관계가 있음이 드러나면서 과학적 방법에도 수학은 중요한 역할을 하고 있다. 노벨 물리학상 수상자 유진 위그너는 그의 에세이 \"The unreasonable effectiveness of mathematics in natural sciences\"에서 인간 세상과 동떨어져있고 현실과 아무 관련이 없다고 여겨지던 수학 중 극히 일부는 뜻밖에도 자연과학과 연관성이 드러나고 과학이론에 효과적인 토대를 마련해 주는데에 대한 놀라움을 표현하였다. 예를 들어, 비유클리드 기하학과 3차원 이상의 임의의 차원에서 기하학을 탐구했던 미분 기하학은 당시에는 현실과 연관성을 가지지 않았으나 먼 훗날 일반상대성이론이 4차원 기하학을 필요로 함에 따라, 물리적 세상과 연관이 있음이 밝혀졌다. 또한 게이지이론, 양자장론 등에도 미분 기하학은 필수적이다.\\n또한 수학은 음악이나 미술 등 예술과도 관련이 있다. 피타고라스는 두 정수의 비율이 듣기 좋은 소리가 난다는 점을 가지고 피타고라스 음계를 만들었다. 중세시대에도 음악과 수학을 밀접하게 연관시켰으며 성 빅토르의 후고는 “음악은 조화다”라고 했고, 성 트론드의 루돌프는 “음악은 조화의 토대(ratio)다”라고 쓴 바 있다. 조화가 반드시 소리로 표현될 필요는 없고 소리의 음악은 음악의 형식 중 하나에 불과했다. 소리에 대해 다루었던 중세의 저술가들이 있는가 하면, 조화와 비례의 추상적 이론만을 다루고 소리에는 거의 관심을 보이지 않았던 저술가들도 있었다. 청각적인 면과 추상적인 면이라는 음악의 이런 이중적 측면은 고대의 음악이론보다는 중세의 음악이론에서 큰 특징이 되었다. 또한 현대 음악을 군(群,group)같은 수학적 대상을 이용해 분석하기도 한다. 원근법은 사영 기하학에 해당한다. 미술 사조 중 하나인 입체파도 기하학의 영향을 받았다.'}\n",
            "score: 1.5310912 source:: {'id': '187', 'revid': '661879', 'url': 'https://ko.wikipedia.org/wiki?curid=187', 'title': '구글', 'text': '구글 LLC()는 전 세계의 정보를 체계화하여 모든 사용자가 편리하게 이용할 수 있도록 하는 것을 목표로 하는 미국의 다국적 기업이다. 검색 서비스 제공을 주력으로 한다. 구글 검색은 2018년 5월 기준 전 세계 검색량의 90%를 점유하고 있다. 2008년 웹 페이지 인덱스 수가 1조를 돌파했다.\\n역사.\\n1998년에 BackRub 이라는 이름으로 검색 서비스를 시작하였다. 이후 구글(Google)로 이름을 변경하였는데, 이는 10100을 뜻하는 구골로 등록하려다 실수로 사명을 잘못 표기한 것에서 지금까지 쓰이고있다. 매우 큰 유한수를 의미하는 이 단어는 \\'엄청난 규모의 검색엔진을 만들겠다\\'는 설립자들의 목표와 맞아 떨어졌으나 당시 이미 \\'구골\\'이라는 사이트가 존재하여 구글이 되었다. \\'왓박스\\'(whatbox)라는 이름도 고려되었으나 포르노 사이트인 웻박스(watbox)와 유사해 제외되었다.\\n구글은 세계 최대의 검색엔진으로 현재 나스닥에 상장된 기업이다. 특히 영미권에서는 독보적인 점유율을 보이고 있다.\\n2006년, 구글은 유튜브라는 세계 최대의 동영상 공유 및 스트리밍 사이트를 인수했다. 같은해 11월, 유튜브의 하루 방문자는 2,500만 명으로 추정되었다. 2007년, 구글은 최고의 디지털 마케팅 회사인 더블클릭을 인수했고, 같은해 더블클릭은 하루 170억 개의 광고를 집행했다. 그리하여 구글은 2008년, 증권거래위원회에 보낸 공개문서에서 구글은 \"우리는 기술회사로 시작해서 소프트웨어, 기술, 인터넷, 광고, 미디어 회사가 모두 하나로 합해진 기업으로 진화했다\" 고 말했다. 230억 달러에 달하는 미국 온라인 광고 시장과 540억 달러에 달하는 전 세계 온라인 광고 시장의 40%를 독식했다.\\n구글은 PDF, 포스트스크립트, 마이크로소프트 워드, 어도비 플래시 문서들을 포함한 웹 문서 검색 서비스를 제공한다. 이 외에 구글 이미지 검색, Google 뉴스 한국, 구글 뉴스그룹, 구글 웹 디렉토리, 구글 비디오, Froogle 서비스에서 이름이 변경된 상품 검색, 구글 맵, 구글 어스 등의 주요 검색 서비스가 있다.\\n또한 검색 서비스 외에 추가적인 서비스들을 제공하는데 이에는 2004년 시작된 이메일 서비스인 Gmail 과 YouTube, 피카사, Google 사전, Google 리더, iGoogle, 기업 사용자를 위해서 각종 웹 애플리케이션을 제공하는 구글 앱스 등이 있다.\\n2010년 세계 포털 사이트에 야후(Yahoo)로 제쳤고, 구글에 앞질렀다.\\n2011년, 모토로라 인코퍼레이티드는 휴대전화사업과 본사의 사업부분이 불안정적으로 운영됨에 대한 걱정과 사업부 실적의 부진으로 인해 사업부가 모토로라 인코퍼레이티드의 자회사로 분리하기로 결정하였다.\\n2011년 모토로라는 더 발전적이고 공격적인 사업을 위해 새로운 모기업을 찾게되고, 대상기업이 된 구글은 인수할때 각 주당 63%의 경영권 프리미엄을 얹어 총 125억 달러(당시 한화 약 13조5천125억원)에 인수하기로 결정하였다.\\n구글의 인수에도 불구하고, 모토로라는 여전히 기존 장치의 안드로이드 버전 업그레이드 서비스와 신제품을 출시하기 위해 노력하고 있다.\\n2014년, 구글은 모토로라의 분리된 사업부 중 \\'스마트폰 제조분야\\'를 매각하기로 결정하였고 레노버에게 총 29억 1천만 달러(당시 한화 약 3조100억원)를 매각하기로 결정하였다.\\n검색 원리.\\n크롤링.\\n구글봇이라는 이름의 웹 크롤러는 사용자가 검색하기 전에 수천억 개에 달하는 웹페이지에서 정보를 모아 이를 검색 색인에 정리한다.\\n크롤러는 과거 크롤링으로 만들어진 웹 주소 목록과 웹사이트 소유자가 제공한 사이트맵에서 크롤링을 시작한다. 웹사이트를 방문한 크롤러는 사이트에 있는 링크를 사용하여 다른 페이지를 찾는다. 크롤링하는 동안 새로운 사이트, 기존 사이트의 변경사항, 깨진 링크를 주의 깊게 살핀다. 크롤링할 사이트, 크롤링 횟수 및 각 사이트에서 가져올 페이지 수는 컴퓨터 프로그램이 결정한다.\\n구글에서는 사이트 소유자에게 웹마스터 도구를 제공하여 사이트 소유자가 구글에서 사이트를 크롤링하는 방법의 세부 사항까지 스스로 결정할 수 있도록 한다. 사이트 소유자는 페이지를 어떻게 처리할 것인지에 관해 자세한 지침을 제공할 수 있으며, 재크롤링을 요청하거나 \\'robots.txt\\'라는 파일을 사용하여 아예 페이지가 크롤링되지 않도록 할 수도 있다. 구글은 비용을 받고 특정 사이트를 더 자주 크롤링하지 않으며 사용자에게 최고의 검색결과를 보장하기 위하여 모든 웹사이트에 동일한 도구를 제공한다.\\n검색 알고리즘.\\n사용자에게 수십억 개의 웹페이지가 아닌 질문에 대한 답을 제공하기 위해, 구글의 검색 알고리즘은 크게 다섯 가지 방법을 활용한다. 검색어의 의미를 이해하기 위해 단어를 분석하기, 검색어와 일치하는 정보가 포함된 웹페이지를 검색하기, 페이지의 유용성을 평가하여 순위를 매기기, 사용자의 위치나 이전 검색 기록과 같은 맥락을 고려하여 사용자에게 알맞은 검색 결과를 제공하기, 검색 결과가 사용자의 검색 유형에 유용한지 고려하여 최상의 결과를 제공한다.\\n광고.\\n구글은 광고주에게 구글 애즈 프로그램을 제공한다. 이 프로그램을 통해 입찰함으로써 검색 결과 옆에 뜨는 텍스트 광고를 구매할 수 있다. 희소성이 높은 키워드는 클릭당 광고비가 더 비싸게 책정된다.\\n애드센스를 통해서 광고를 하고 싶어하는 회사와 관련 사이트를 연결하는 역할을 한다. 애드워즈와 유사한 자동화 프로그램을 통해 둘을 연결해 준다.\\n구글은 클릭당 지불 데이터를 가지고 해당 광고를 클릭 할 때만 비용을 내도록 한다.\\n구글 애널리틱스(Google Analytics)는 광고주에게 해당 광고의 효과를 즉시 확인 할 수 있는 무료 툴을 제공한다. 이 프로그램은 매시간 클릭수와 판매량, 해당 키워드의 트래픽, 클릭이 판매로 이어진 비율 등 광고 효과를 즉각 확인 할 수 있게 해준다.\\n미디어 업체로 하여금 광고 판매에 들어가는 비용을 줄임으로써 롱테일(long tail)이라는 형태로 변화하도록 한다. 그렇게 한다면 기존에는 광고를 잘 하지 않던 이들까지도 타킷팅이 잘 된 저렴한 광고를 구매하도록 끌어들일 수 있다는 것이다.\\n구글은 사용자들에게 신문이나 책, 잡지를 자유롭게 검색하도록 권장한다. 해당 발행물들 역시 검색 트래픽을 활용해서 무료로 자신들을 홍보하고 광고를 판매해 수익을 창출한다. TV 방송사나 영화사들은 유튜브를 홍보채널 겸 온라인 배급시스템으로 활용하도록 권장한다. 광고주들에게는 구글이 2007년에 인수한 디지털 광고 서비스 업체 더블클릭(Doubleclick)을 통해 온라인 광고를 하도록 권한다.\\n구글의 수입은 2004년 32억 달러이던 것이 2007년에는 166억 달러로 뛰었다. 세계적 불황을 비웃기라도 하듯, 구글은 2008년에 42억 달러의 수익을 거두었고 매출은 218억 달러로 상승했다. 그리고 그 가운데 97%가 광고 수입이었다.\\n2008년, 구글의 광고 수입은 5개 방송사(CBS, NBC, ABC, FOX, CW)의 광고 수입을 합한 것에 맞먹었다. 2011년에 이르면 미국 내 웹 광고는 600억 달러(전체 13%)에 달할 것으로 전망된다. 게다가 구글은 tv, 라디오, 신문에 광고를 판매함으로써 시장점유율을 가일층 확대할 사업구상을 이미 개시했다.\\n사용자가 텍스트 광고를 클릭할 때만 광고료를 부과해서 광고주들 중에서 우군을 확보했고, 무료이자 2009년 초반까지 광고가 붙지 않았던 구글 뉴스로 뉴스독자들 중에서 우군을 확보했으며, 광고 수익과 신규 고객을 발생시켜 줌으로써 웹사이트와 소규모 사업자들 중에서 우군을 확보했다. 구글은 두 번째 경매 프로그램 애드센스 때부터 수입의 20%만 자기 주머니에 넣고 나머지는 웹사이트들에게 돌려 주었다. 2008년에 구글은 총 50억 달러가 넘는 돈을 수십만에 달하는 \\'파트너들\\'에게 제공했다.\\n그 밖의 서비스.\\nG메일, 구글 뉴스, 구글 어스, 구글 맵스, 구글 비디오, 구글 번역, 피카사(Picasa-디지털 사진 공유), 구글 클래스룸, 구글 북스(발행된 모든 책 검색), 구글 트렌드 (검색량 통계 제공), 오컷(Orkut-인맥, 친목 사이트), 여기에 데스크톱(Desktop)이나 문서도구(Docs), 구글 플레이같은 \\'클라우드 컴퓨팅(cloud computing)\\' 응용 프로그램까지 제공한다.\\n구글에서 사용하는 컴퓨터는 보통 PC들로 구성된 컴퓨터 클러스터들인데, 이 클러스터들은 일을 병렬적으로 처리하여 방대한 양의 데이터베이스를 처리한다. 특히 여러 대의 PC를 운영하면서 계속적인 데이터베이스를 처리하기 위해 한 컴퓨터에 오류가 났을 경우 그 컴퓨터는 꺼지고, 다른 컴퓨터가 일을 계속 처리하도록 한다. 구글은 이러한 방식이 거대하고 비싼 컴퓨터(서버)를 대신하는 대안이 될 수 있음을 증명했고 이러한 방식을 지금도 사용하고 있다.\\n최근에는 인공지능 사업에도 투자를 하여 알파고나 무인자동차의 영역에서 활발히 활동하고 있다.\\n구글의 문화.\\n구글의 철학은 \"You can make money without doing evil.\"(악해지지 않고도 돈을 벌 수 있다.)와, \"You can be serious without a suit.\"(정장 없이도 진지해질 수 있다) 그리고 \"Work should be challenging and the challenge should be fun.\"(일은 도전이어야 하고 도전은 재미가 있어야 한다)이다. \\'Don\\'t Be Evil\\' (나쁜 짓을 하지 말자)이라는 철학에도 불구하고 오랜 기간 사용자 컴퓨터 내에 살아 있는 쿠키에 대한 비난으로, 미국의 인권단체 \\'Public Information Research\\' 에 의해, 구글은 빅브라더 상(Big Brother Awards)의 후보가 되기도 했다.\\n구글은 형식을 따지지 않는 자유롭고 재미있는 기업 문화로 잘 알려져 있다. 2007, 2008 구글은 가장 일하기 좋은 장소로 뽑혔다.\\n구글 엔지니어들은 \\'직감\\'으로 결정을 내리지 않는다. 인간관계나 판단력 같은 것은 정량화 할 수 없기 때문이다. 그들은 경험보다는 효율을 중시한다. 그들은 사실과 베타 테스트와 수학적 논리를 추구한다.\\n구글은 지구 온난화 문제에도 관심을 보인다. 구글은 사옥 지붕에 미국 기업 캠퍼스 가운데 가장 큰 태양광 패널을 설치하여 1천 가구에 전력을 공급할 만한 전기를 생산한다. 외부 주차장에 태양발전소를 두어 하이브리드 자동차를 충전할 수 있게 했고, 연비가 좋은 하이브리드 자동차를 구매하는 직원에게는 장려금 (처음에는 5천 달러, 현재는 3천 달러)을 제공한다. 구글은 수익의 1%를 때어내 자선사업 부문인 구글 파운데이션에 보낸다. 넓은 캠퍼스 부지 내에서의 건물 간 이동을 위해 신청에 의해 차량을 제공하기도 하지만, 온실가스 배출을 최소화하고 직원들의 건강에도 이바지하기 위해 구글이 제공하는 자전거가 도처에 배치되어 있다.\\n구글이 1999년 8월 처음 구글플렉스로 이주했을때, 거기에는 \\'직원들이 내부 일에만 집중하게 하겠다\\'는 결의가 반영되어 있었다. 구글플렉스에는 2~3층짜리 나지막한 건물이 모여있고, 건물 밖에는 야외테이블과 벤치, 울창한 나무들, 채소 정원, 사람과 자전거로 활기 넘치는 산책로가 있다. 직원들은 무료 식사와 다과를 즐기고 (매년 구글은 여기에만 7천만 달러 정도를 쓴다), 트레이너가 대기하는 체육관과 마사지실이 붙어 있는 건물들 사이로 이동할 자전거를 지급받는다. 직원들은 커다란 카페테리아 탁자에서 식사하고, 당구대와 에스프레소 기계가 있는 라운지에서 쉰다. 세차나 오일 교환 때문에 캠퍼스를 떠날 필요도 없다. 목요일이면 검진 차량이 찾아오고 뿐만 아니라 이발사, 세탁업자, 보모, 애완동물 도우미, 치과의사, 그리고 무료 검진 담당의도 5명이나 있다. 편안한 좌석에 무선인터넷이 완비된 바이오 디젤 통근 버스가 직원들을 멀게는 샌프란시스코까지 늦은 밤까지 실어 나른다. 노트북 컴퓨터도 살 필요가 없다. 그저 마음에 드는 모델을 고르기만 하면 된다. 여성은 출산 휴가를 5개월간 유급으로 낼 수 있고, 신생아 아빠는 마찬가지로 유급으로 7주 휴가를 낼 수 있다.\\n\"20%\" 시간.\\n모든 구글 엔지니어들은 업무 시간중 20%(주 5일 근무 기준으로 일주일중 하루)를 그들이 흥미로워하는 프로젝트에 사용하도록 권장된다. 몇몇 구글의 새로운 서비스들, 예를 들어 Gmail, 구글 뉴스, Orkut, AdSense는 이러한 직원들의 독립적인 프로젝트들에 의해서 시작되었다. 구글의 검색 제품 및 고객 경험 파트의 부사장인 매리싸 마이어는 스탠퍼드 대학에서의 연설에서 새로 론칭되는 서비스의 50%가 이러한 20% 시간을 통해 시작되었다고 말한 바 있다.\\n기업모토 \"Don\\'t be evil\".\\n간단히 요약하면 돈을 벌때 나쁜일이 아닌 좋은 일을 통해 돈을 벌자는 의미이다.\\n한국법인.\\n구글 코리아()는 2003년 3월부터 한국 시장에 진출하기 시작했다. 2005년에 한국 진출을 선언하였고 2006년에 설립한 기업이다.\\n비판.\\n고객센터의 부재.\\n구글은 한국의 포털사이트인 다음, 네이버와 다르게 고객센터를 두고 있지 않다. 따라서, 구글직원과 직접 연락하는 방법은 없다. 그러나 포럼을 통하여 google employee와 의견 공유가 가능하다.\\n개인정보 유출.\\n블로그, 카페, 웹페이지에서 적었던 글은 구글로봇이 수집하여 보관한다. 이를 삭제하려면 웹마스터도구를 이용해야 하는데, 구글의 삭제조건에 들지 않으면 삭제되지 않는다. 하지만 최근 유럽연합에서 잊힐수 있는 권리에 대해서 인정함에 따라, 이에 맞추어 구글도 지울 수 있도록 구글로봇을 수정하고 있다.\\n블로그 검색.\\n블로그 검색을 통해 블로거의 글을 검색할 수 있다. 다만, 블로그를 폐쇄했어도 자신이 작성했던 글에 대해선 계속 검색이 되어 삭제할 방법이 없다. 설사 웹마스터를 통해 삭제를 했어도 블로그 검색에 있던 글은 영구적으로 삭제가 불가능하며, 글을 재발행하는 방법밖엔 없다.\\n정보통신망 이용촉진 및 정보보호 등에 관한 법률 위반.\\n2014년 3월 20일, 구글 메인페이지에 이와 관련한 내용이 게시되었다. 이에 따르면 구글은 2009년 10월 5일부터 2010년 5월 10일까지 스트리트 뷰 서비스와 관련하여 사용자의 동의 없이 개인정보를 수집하였다고 한다. 이는 정보통신망 이용촉진 및 정보보호 등에 관한 법률을 위반한 것으로 방송통신위원회로부터 시정명령을 받았다.\\n나치의 학살 행위인 홀로코스트 희화화 논란.\\n한국어판 구글 어시스턴트에서 재밌는 얘기를 해달라고 하자 나치의 만행인 홀로코스트를 재밌는 이야기랍시고 유머로서 소비하여 국내에서 논란이 일기도 했다. 홀로코스트가 뭔지 알면 누구나 개그로 하기에는 부적절하다는건 잘 알테다.\\n이에 분노한 네티즌들은 한국어 어시스턴트를 설계한 담당자를 당장 구글로부터 해고하라는 등의 분노를 표출 했으며, 트위터나 여러 SNS에선 구글 어시스턴트 삭제 인증을 하거나 아예 사용도 안 했으며, 더 나아가 아예 안드로이드 스마트폰을 쓰지 말고 아이폰을 쓰자며 불매운동까지 일어났다.\\n결국 이 사건은 독일을 비롯한 해외에도 퍼졌으며 당장 시정하고 사과할 것을 구글에 요구했다. 다행히도 문제가 되는 회화는 어시스턴트에서 지워졌으나 이에 대한 해명은 하지 않았다.\\n구글 계정 연령 조건.\\n구글 계정 나이 요구 사항.\\n구글에 가입하려면 대부분의 국가에서는 13세 이상이어야 한다. 다만 대한민국, 스페인에서는 14세 이상, 베트남에서는 15세 이상, 네덜란드에서는 16세 이상 가입할 수 있다.\\n제품별 연령 요구 사항.\\n일부 구글 서비스는 특정 연령 요건이 있다.'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjyhNG8_mIPX"
      },
      "source": [
        "## (END)\n"
      ]
    }
  ]
}